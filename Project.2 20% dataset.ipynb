{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Harrison\n",
      "[nltk_data]     Lu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from io import StringIO\n",
    "import networkx as nx\n",
    "import re\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize \n",
    "stop_words = set(stopwords.words('english')) \n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier as kNN\n",
    "from sklearn.linear_model import LogisticRegression as logreg\n",
    "from sklearn import svm\n",
    "from sklearn.tree import DecisionTreeClassifier as dectree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# explore data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>ID</th>\n",
       "      <th>date</th>\n",
       "      <th>query</th>\n",
       "      <th>username</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810369</td>\n",
       "      <td>mon apr 06 22:19:45 pdt 2009</td>\n",
       "      <td>no_query</td>\n",
       "      <td>_thespecialone_</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>mon apr 06 22:19:49 pdt 2009</td>\n",
       "      <td>no_query</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>mon apr 06 22:19:53 pdt 2009</td>\n",
       "      <td>no_query</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@kenichan i dived many times for the ball. man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>mon apr 06 22:19:57 pdt 2009</td>\n",
       "      <td>no_query</td>\n",
       "      <td>ellectf</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>mon apr 06 22:19:57 pdt 2009</td>\n",
       "      <td>no_query</td>\n",
       "      <td>karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment          ID                          date     query  \\\n",
       "0          0  1467810369  mon apr 06 22:19:45 pdt 2009  no_query   \n",
       "1          0  1467810672  mon apr 06 22:19:49 pdt 2009  no_query   \n",
       "2          0  1467810917  mon apr 06 22:19:53 pdt 2009  no_query   \n",
       "3          0  1467811184  mon apr 06 22:19:57 pdt 2009  no_query   \n",
       "4          0  1467811193  mon apr 06 22:19:57 pdt 2009  no_query   \n",
       "\n",
       "          username                                               text  \n",
       "0  _thespecialone_  @switchfoot http://twitpic.com/2y1zl - awww, t...  \n",
       "1    scotthamilton  is upset that he can't update his facebook by ...  \n",
       "2         mattycus  @kenichan i dived many times for the ball. man...  \n",
       "3          ellectf    my whole body feels itchy and like its on fire   \n",
       "4           karoli  @nationwideclass no, it's not behaving at all....  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./dataset/sentiment140/data.csv', encoding='latin-1', header = None)\n",
    "df.columns = ['sentiment', 'ID', 'date', 'query', 'username', 'text']\n",
    "\n",
    "df = df.applymap(lambda s: s.lower() if type(s) == str else s)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# splitting entire dataset\n",
    "\n",
    "not used in experiment below yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "dfTrain = df.sample(frac = 0.8, random_state = 20)\n",
    "dfTest = df.drop(dfTrain.index)\n",
    "\n",
    "dfGraphModel = dfTrain.sample(frac = 0.5, random_state = 20)\n",
    "dfDM = dfTrain.drop(dfGraphModel.index)\n",
    "\n",
    "#subset of the dfTrain dataset, split into positive, negative, and neutral tweets\n",
    "pos = dfGraphModel.loc[df['sentiment'] == 4]\n",
    "neg = dfGraphModel.loc[df['sentiment'] == 0]\n",
    "neut = dfGraphModel.loc[df['sentiment'] == 2]\n",
    "\n",
    "posText = {line[\"ID\"]: line[\"text\"] for index, line in pos.iterrows()}\n",
    "negText = {line[\"ID\"]: line[\"text\"] for index, line in neg.iterrows()}\n",
    "\n",
    "posWords = [line.rstrip('\\n') for line in open('./dataset/positive-words.txt') if line.split() and list(line)[0] != ';']\n",
    "negWords = [line.rstrip('\\n') for line in open('./dataset/negative-words.txt') if line.split() and list(line)[0] != \";\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# filtering by target word \"food\"\n",
    "also removing handles. \n",
    "\n",
    "result in 4000 something tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>query</th>\n",
       "      <th>username</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>313228</th>\n",
       "      <td>0</td>\n",
       "      <td>2001705696</td>\n",
       "      <td>tue jun 02 01:47:24 pdt 2009</td>\n",
       "      <td>no_query</td>\n",
       "      <td>jkayp</td>\n",
       "      <td>show girl! whatcha gotta do! last tour? omg wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253601</th>\n",
       "      <td>0</td>\n",
       "      <td>1984029518</td>\n",
       "      <td>sun may 31 14:18:12 pdt 2009</td>\n",
       "      <td>no_query</td>\n",
       "      <td>bp0203</td>\n",
       "      <td>ex boyfriends suck -pete! alien-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1041037</th>\n",
       "      <td>4</td>\n",
       "      <td>1957027349</td>\n",
       "      <td>thu may 28 23:18:58 pdt 2009</td>\n",
       "      <td>no_query</td>\n",
       "      <td>tsarnick</td>\n",
       "      <td>one like best?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217422</th>\n",
       "      <td>0</td>\n",
       "      <td>1975936563</td>\n",
       "      <td>sat may 30 16:13:32 pdt 2009</td>\n",
       "      <td>no_query</td>\n",
       "      <td>lisaduco</td>\n",
       "      <td>damn back hella hurtting work</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495067</th>\n",
       "      <td>0</td>\n",
       "      <td>2185120448</td>\n",
       "      <td>mon jun 15 16:55:01 pdt 2009</td>\n",
       "      <td>no_query</td>\n",
       "      <td>anda_mkefa</td>\n",
       "      <td>days already</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         sentiment          id                          date     query  \\\n",
       "313228           0  2001705696  tue jun 02 01:47:24 pdt 2009  no_query   \n",
       "253601           0  1984029518  sun may 31 14:18:12 pdt 2009  no_query   \n",
       "1041037          4  1957027349  thu may 28 23:18:58 pdt 2009  no_query   \n",
       "217422           0  1975936563  sat may 30 16:13:32 pdt 2009  no_query   \n",
       "495067           0  2185120448  mon jun 15 16:55:01 pdt 2009  no_query   \n",
       "\n",
       "           username                                               text  \n",
       "313228        jkayp  show girl! whatcha gotta do! last tour? omg wa...  \n",
       "253601       bp0203                   ex boyfriends suck -pete! alien-  \n",
       "1041037    tsarnick                                     one like best?  \n",
       "217422     lisaduco                      damn back hella hurtting work  \n",
       "495067   anda_mkefa                                       days already  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfReduced = df.sample(frac = 0.2, random_state = 20)\n",
    "\n",
    "subjectTweetsDict = {} # key = index in original df and value = tweet info (sentiment, id, date, query, username, full tweet)\n",
    "filteredTweets = {} # key = index in original df and value = filtered tweet\n",
    "count = 0\n",
    "for row in dfReduced.itertuples():\n",
    "    subjectTweetsDict[row[0]] = list(row)[1:7]\n",
    "    word_tokens = str(row[6]).split() #split by white space\n",
    "    filtered_sentence = [w for w in word_tokens if not w in stop_words] \n",
    "    filtered_sentence = [] \n",
    "    i = 0\n",
    "    while i < len(word_tokens):\n",
    "        if '@' in word_tokens[i]: #Taking out handles from tweets\n",
    "            i = i + 1\n",
    "        elif word_tokens[i] not in stop_words:\n",
    "            filtered_sentence.append(word_tokens[i])\n",
    "        i = i + 1\n",
    "    filteredTweets[row[0]] = filtered_sentence\n",
    "#print(subjectTweetsDict)\n",
    "#df2 = pd.DataFrame(data=subjectTweetsDict, columns = ['index', 'sentiment', 'id', 'date', 'query', 'username', 'tweet'])\n",
    "dfSubject= pd.DataFrame.from_dict(subjectTweetsDict, orient = 'index', columns = ['sentiment', 'id', 'date', 'query', 'username', 'text'])\n",
    "for key, value in filteredTweets.items():\n",
    "    filteredString = ' '.join(value)\n",
    "    dfSubject.at[key, \"text\"] = filteredString\n",
    "\n",
    "dfSubject.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## splitting our dataset into training, testing set.\n",
    "split training into creating graph model, as well as creating the data mining model. \n",
    "split graph model into positive, negative, and neutral.\n",
    "\n",
    "no neutral tweets, as we have found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "dfTrain = dfSubject.sample(frac = 0.8, random_state = 20)\n",
    "dfTest = dfSubject.drop(dfTrain.index)\n",
    "\n",
    "dfGraphModel = dfTrain.sample(frac = 0.6, random_state = 20)\n",
    "dfDM = dfTrain.drop(dfGraphModel.index)\n",
    "\n",
    "posSubject = dfGraphModel.loc[dfSubject['sentiment'] == 4]\n",
    "negSubject = dfGraphModel.loc[dfSubject['sentiment'] == 0]\n",
    "neutSubject = dfGraphModel.loc[dfSubject['sentiment'] == 2] #there is no neutral"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# writing functions to evaluate how each model works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "'''this function creates the word graph given the text in the tweet and the \n",
    "frame that is used to create the graph model. Can accept both an array of strings to \n",
    "treat as one long string, or a single string.'''\n",
    "\n",
    "def createGraphFromTweet(text, frame):\n",
    "    wordGraph = nx.DiGraph()\n",
    "    if type(text) == str:\n",
    "        createGraph(text, wordGraph, frame)\n",
    "    if type(text) == list:\n",
    "        for element in text:\n",
    "            createGraph(element, wordGraph, frame)\n",
    "    return wordGraph\n",
    "\n",
    "'''helper function- NOT FOR USE.'''\n",
    "def createGraph(text, wordGraph, frame):\n",
    "    if text:\n",
    "        text = re.sub(r'[^\\w\\s]', '', str(text))\n",
    "        text = text.split()\n",
    "        try:\n",
    "            if len(text) == 1:\n",
    "                wordGraph.add_edge(text[0], text[0], weight = 1)\n",
    "            for x in range(len(text) - frame):\n",
    "                for y in range(1, frame + 1):\n",
    "                    n1 = text[x]\n",
    "                    n2 = text[x+y]\n",
    "                    if wordGraph.has_edge(n1, n2):\n",
    "                        wordGraph[n1][n2]['weight'] = wordGraph[n1][n2]['weight'] + 1\n",
    "                    else:\n",
    "                        wordGraph.add_edge(n1, n2, weight = 1)\n",
    "            for x in reversed(range(1, frame + 1)):\n",
    "                for y in reversed(range(1, x)):\n",
    "                    n1 = text[len(text) - x]\n",
    "                    n2 = text[len(text) - y]\n",
    "                    if wordGraph.has_edge(n1, n2):\n",
    "                        wordGraph[n1][n2]['weight'] = wordGraph[n1][n2]['weight'] + 1\n",
    "                    else:\n",
    "                        wordGraph.add_edge(n1, n2, weight = 1)\n",
    "        except IndexError:\n",
    "            return createGraph(text, wordGraph, frame-1)\n",
    "        return wordGraph\n",
    "    else:\n",
    "        return wordGraph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Harrison Lu\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py:2: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \n",
      "C:\\Users\\Harrison Lu\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py:3: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "'''extracting text from the dataframe'''\n",
    "posArrayText = posSubject.as_matrix(columns = posSubject.columns[-1:]).flatten().tolist()\n",
    "negArrayText = negSubject.as_matrix(columns = negSubject.columns[-1:]).flatten().tolist()\n",
    "\n",
    "'''putting text into one large graph'''\n",
    "posWordGraph = createGraphFromTweet(posArrayText, 3)\n",
    "negWordGraph = createGraphFromTweet(negArrayText, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "'''GRAPH SIMILARITY FUNCTIONS'''\n",
    "\n",
    "'''counts the number of identical edges between two graphs, normalizes by the minimum number of nodes in either graph'''\n",
    "def edgeSimilarity(inputGraph, model):\n",
    "    count = 0\n",
    "    for edge in inputGraph.edges():\n",
    "        n1, n2 = edge\n",
    "        if model.has_edge(n1, n2): \n",
    "            count += 1\n",
    "    try:\n",
    "        return count/min(len(inputGraph), len(model))\n",
    "    except ZeroDivisionError:\n",
    "        return 0\n",
    "\n",
    "'''returns maximum common subgraph of inputs'''\n",
    "def getMCS(graphModel, tweetGraph):\n",
    "    matching_graph = nx.DiGraph()\n",
    "    for n1, n2 in tweetGraph.edges():\n",
    "        if graphModel.has_edge(n1, n2):\n",
    "            matching_graph.add_edge(n1, n2, weight = tweetGraph[n1][n2]['weight'])\n",
    "    edgeList = list(matching_graph.edges())\n",
    "    edgeListCopy = edgeList[:]\n",
    "    nodeList = list(matching_graph.nodes())\n",
    "    visited = []\n",
    "    graphArray = []\n",
    "    while nodeList:\n",
    "        G = nx.DiGraph()\n",
    "        parentNode = nodeList.pop(0)\n",
    "        toRemove = []\n",
    "        for edge in edgeList:\n",
    "            n1, n2 = edge\n",
    "            if parentNode == n1:\n",
    "                if n2 in nodeList:\n",
    "                    G.add_edge(n1, n2)\n",
    "                    toRemove.append(edge)\n",
    "                    visited.append(n2)\n",
    "                else:\n",
    "                    for graph in graphArray:\n",
    "                        if n2 in graph.nodes():\n",
    "                            graph.add_edge(n1, n2)\n",
    "            edgeList = [e for e in edgeList if e not in toRemove]\n",
    "            toRemove = []\n",
    "            while visited:\n",
    "                node = visited.pop(0)\n",
    "                if node in nodeList:\n",
    "                    nodeList.remove(node)\n",
    "                for edge in edgeList:\n",
    "                    n1, n2 = edge\n",
    "                    if node == n1: \n",
    "                        G.add_edge(n1, n2)\n",
    "                        toRemove.append(edge)\n",
    "                        visited.append(n2)\n",
    "                edgeList = [e for e in edgeList if e not in toRemove]\n",
    "                toRemove = []\n",
    "        if len(G) != 0:\n",
    "            graphArray.append(G)\n",
    "\n",
    "    size = 0 \n",
    "    returnGraph = nx.DiGraph()\n",
    "    for graph in graphArray:\n",
    "        if len(graph) > size:\n",
    "            returnGraph = graph\n",
    "            size = len(graph)\n",
    "    return returnGraph\n",
    "        \n",
    "\n",
    "'''returns number of common nodes in MCS and model graph, normalized by minimum number of nodes'''\n",
    "def MCSNS(mcs_graph, graphModel, tweetGraph):\n",
    "    try:\n",
    "        return len(mcs_graph)/min(len(graphModel),len(tweetGraph))\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "'''returns number of common edges in MCS and model graph, normalized by minimum number of nodes'''\n",
    "def MCSUES(mcs_graph, graphModel, tweetGraph): \n",
    "    try:\n",
    "        return len(mcs_graph.edges())/min(len(graphModel),len(tweetGraph))\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "'''returns number of common edges in the MCS and model graph, taking direction into account,\n",
    "normalized by minimum number of nodes'''\n",
    "def MCSDES(mcs_graph, graphModel, tweetGraph): \n",
    "    count = 0\n",
    "    for e1,e2 in mcs_graph.edges():\n",
    "        if tweetGraph.has_edge(e1,e2) and graphModel.has_edge(e1,e2):\n",
    "            count+=1\n",
    "    try:\n",
    "        return count/min(len(graphModel),len(tweetGraph))\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "'''tf-idf helper function'''\n",
    "def calcTotalWords(model):\n",
    "    total = 0\n",
    "    for e1,e2 in model.edges(): #total number of edges = sum of weights\n",
    "        total += model[e1][e2]['weight']\n",
    "    return total\n",
    "\n",
    "'''tf-idf method for coming up with vectors, max edge value is taken as representative of\n",
    "the entire tweet model. Idea is that positive tweet should have a higher pos max than a neg max'''\n",
    "def tf_idf_max(tweetModel, posModel, negModel): #returns max score for each tweet model\n",
    "    maxPosVal = []\n",
    "    maxNegVal = []\n",
    "    totalPosEdges = calcTotalWords(posModel)\n",
    "    totalNegEdges = calcTotalWords(negModel)\n",
    "    for e1,e2 in tweetModel.edges():\n",
    "        if posModel.has_edge(e1, e2) and negModel.has_edge(e1, e2):      #both models have the edge\n",
    "            idf = math.log(1)                                #idf = 2 models, both have the edge -> 2/2 = 1\n",
    "            tf_pos = posModel[e1][e2]['weight'] / totalPosEdges\n",
    "            tf_neg = negModel[e1][e2]['weight'] / totalNegEdges\n",
    "            pos_score = idf * tf_pos\n",
    "            neg_score = idf * tf_neg\n",
    "            maxPosVal.append(pos_score)\n",
    "            maxNegVal.append(neg_score)\n",
    "        elif posModel.has_edge(e1, e2) or negModel.has_edge(e1, e2):          #only one of the models has the edge\n",
    "            idf = math.log(2)                              #idf: 2 models, only 1 has the edge -> 2/1 = 2\n",
    "            if posModel.has_edge(e1, e2):\n",
    "                tf_pos = posModel[e1][e2]['weight'] / totalPosEdges\n",
    "                pos_score = idf * tf_pos\n",
    "                maxPosVal.append(pos_score)\n",
    "            else:\n",
    "                tf_neg = negModel[e1][e2]['weight'] / totalNegEdges\n",
    "                neg_score = idf * tf_neg\n",
    "                maxNegVal.append(neg_score)\n",
    "    if len(maxPosVal) == 0:\n",
    "        maxPosVal.append(0)\n",
    "    if len(maxNegVal) == 0:\n",
    "        maxNegVal.append(0)\n",
    "    return max(maxPosVal), max(maxNegVal)\n",
    "\n",
    "\n",
    "'''tf-idf method for coming up with vectors, avg edge value is taken as representative of\n",
    "the entire tweet model.'''\n",
    "def tf_idf_avg(tweetModel, posModel, negModel): #returns average tfidf score for each model\n",
    "    totalPosEdges = calcTotalWords(posModel)\n",
    "    totalNegEdges = calcTotalWords(negModel)\n",
    "    negModelSum = 0\n",
    "    posModelSum = 0\n",
    "    totalPosEdgesTweet = 0\n",
    "    totalNegEdgesTweet = 0\n",
    "    for e1,e2 in tweetModel.edges():\n",
    "        if posModel.has_edge(e1, e2) and negModel.has_edge(e1, e2):      #both models have the edge\n",
    "            idf = math.log(1)                                #idf = 2 models, both have the edge -> 2/2 = 1\n",
    "            tf_pos = posModel[e1][e2]['weight'] / totalPosEdges\n",
    "            tf_neg = negModel[e1][e2]['weight'] / totalNegEdges\n",
    "            pos_score = idf * tf_pos\n",
    "            neg_score = idf * tf_neg\n",
    "            posModelSum += pos_score\n",
    "            negModelSum += neg_score\n",
    "            totalPosEdgesTweet += 1\n",
    "            totalNegEdgesTweet += 1\n",
    "        elif posModel.has_edge(e1, e2) or negModel.has_edge(e1, e2):          #only one of the models has the edge\n",
    "            idf = math.log(2)                              #idf: 2 models, only 1 has the edge -> 2/1 = 2\n",
    "            if posModel.has_edge(e1, e2):\n",
    "                tf_pos = posModel[e1][e2]['weight'] / totalPosEdges\n",
    "                pos_score = idf * tf_pos\n",
    "                posModelSum += pos_score\n",
    "                totalPosEdgesTweet += 1\n",
    "            else:\n",
    "                tf_neg = negModel[e1][e2]['weight'] / totalNegEdges\n",
    "                neg_score = idf * tf_neg\n",
    "                negModelSum += neg_score\n",
    "                totalNegEdgesTweet += 1\n",
    "\n",
    "    if totalPosEdgesTweet == 0:\n",
    "        average_tfidf_pos = 0\n",
    "    else:\n",
    "        average_tfidf_pos = posModelSum / totalPosEdgesTweet\n",
    "    if totalNegEdgesTweet == 0:\n",
    "        average_tfidf_neg = 0\n",
    "    else:\n",
    "        average_tfidf_neg = negModelSum / totalNegEdgesTweet\n",
    "    \n",
    "    return average_tfidf_pos, average_tfidf_neg\n",
    "\n",
    "'''weight * ((pos/neg)(pos + neg)). idea is that number of times a word shows up in a positive\n",
    "vs negative graph matters. eg, if a term shows up an equal number of times in a pos graph as a \n",
    "neg graph, then it's a neutral word. '''\n",
    "def tf_idf2(tweetModel, posModel, negModel): #harrison's method\n",
    "    allPosScore = []\n",
    "    allNegScore = []\n",
    "    for e1, e2 in tweetModel.edges():\n",
    "        weight_tweet = tweetModel[e1][e2]['weight']\n",
    "        if posModel.has_edge(e1, e2) and negModel.has_edge(e1, e2):\n",
    "            weight_pos = posModel[e1][e2]['weight']\n",
    "            weight_neg = negModel[e1][e2]['weight']\n",
    "            pos_score = weight_tweet * ((weight_pos/weight_neg)/(weight_pos + weight_neg))\n",
    "            neg_score = weight_tweet *((weight_neg/weight_pos)/(weight_pos + weight_neg))\n",
    "            allPosScore.append(pos_score)\n",
    "            allNegScore.append(neg_score)\n",
    "        elif posModel.has_edge(e1, e2) or negModel.has_edge(e1, e2):\n",
    "            if posModel.has_edge(e1, e2):\n",
    "                weight_pos = posModel[e1][e2]['weight']\n",
    "                weight_neg = 1\n",
    "                pos_score = weight_tweet * ((weight_pos/weight_neg)/(weight_pos + weight_neg))\n",
    "                neg_score = weight_tweet *((weight_neg/weight_pos)/(weight_pos + weight_neg))\n",
    "            else:\n",
    "                weight_pos = 1\n",
    "                weight_neg = negModel[e1][e2]['weight']\n",
    "                pos_score = weight_tweet * ((weight_pos/weight_neg)/(weight_pos + weight_neg))\n",
    "                neg_score = weight_tweet *((weight_neg/weight_pos)/(weight_pos + weight_neg))\n",
    "            allPosScore.append(pos_score)\n",
    "            allNegScore.append(neg_score)\n",
    "    if len(allPosScore) == 0:\n",
    "        allPosScore.append(0)\n",
    "    if len(allNegScore) == 0:\n",
    "        allNegScore.append(0)\n",
    "    return max(allPosScore), max(allNegScore)\n",
    "\n",
    "def calculateNumberOfGraphs(e1, e2, graph):\n",
    "    count = 0\n",
    "    for g in graph:\n",
    "        if g.has_edge(e1,e2):\n",
    "            count+=1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''generates the feature vectors and labels (posValue, negValue).\n",
    "   -dataframeDict is the dataframe above turned into a dictionary, with ID as \n",
    "   key and the rest of the information as value, stored as a nested dictionary\n",
    "   -posWordGraph/negWordGraph are our pos/neg graph models\n",
    "   -metric type refers to one of the above functions listed in the above cell block'''\n",
    "def generateWordGraphVectors(dataframeDict, posWordGraph, negWordGraph, metricType):\n",
    "    X = []\n",
    "    y = []\n",
    "    count = 0\n",
    "    for key, value in dataframeDict.items():\n",
    "        if value['text']:\n",
    "            y.append(value['sentiment'])\n",
    "            wordGraph = createGraphFromTweet(value['text'], 4)\n",
    "            posNegArray = []\n",
    "            if metricType == \"edge\":\n",
    "                posNegArray.append(edgeSimilarity(wordGraph, posWordGraph))\n",
    "                posNegArray.append(edgeSimilarity(wordGraph, negWordGraph))\n",
    "            elif metricType == \"MCSNS\":\n",
    "                mcs_graph = getMCS(posWordGraph, wordGraph)\n",
    "                posNegArray.append(MCSNS(mcs_graph, wordGraph, posWordGraph))\n",
    "                mcs_graph = getMCS(negWordGraph, wordGraph)\n",
    "                posNegArray.append(MCSNS(mcs_graph, wordGraph, negWordGraph))\n",
    "            elif metricType == \"MCSUES\":\n",
    "                mcs_graph = getMCS(posWordGraph, wordGraph)\n",
    "                posNegArray.append(MCSUES(mcs_graph, wordGraph, posWordGraph))\n",
    "                mcs_graph = getMCS(negWordGraph, wordGraph)\n",
    "                posNegArray.append(MCSUES(mcs_graph, wordGraph, negWordGraph))\n",
    "            elif metricType == \"MCSDES\":\n",
    "                mcs_graph = getMCS(posWordGraph, wordGraph)\n",
    "                posNegArray.append(MCSDES(mcs_graph, wordGraph, posWordGraph))\n",
    "                mcs_graph = getMCS(negWordGraph, wordGraph)\n",
    "                posNegArray.append(MCSDES(mcs_graph, wordGraph, negWordGraph))\n",
    "            elif metricType == \"TFIDF_max\":\n",
    "                pos_avg, neg_avg = tf_idf_max(wordGraph, posWordGraph, negWordGraph)\n",
    "                posNegArray.append(pos_avg)\n",
    "                posNegArray.append(neg_avg)\n",
    "            elif metricType == \"TFIDF_avg\":\n",
    "                pos_avg, neg_avg = tf_idf_avg(wordGraph, posWordGraph, negWordGraph)\n",
    "                posNegArray.append(pos_avg)\n",
    "                posNegArray.append(neg_avg)\n",
    "            elif metricType == \"TFIDF_2\":\n",
    "                pos_avg, neg_avg = tf_idf2(wordGraph, posWordGraph, negWordGraph)\n",
    "                posNegArray.append(pos_avg)\n",
    "                posNegArray.append(neg_avg)\n",
    "            elif metricType == \"TFIDF_3\":\n",
    "                pos_avg, neg_avg = tf_idf3(wordGraph, posWordGraph, negWordGraph)\n",
    "                posNegArray.append(pos_avg)\n",
    "                posNegArray.append(neg_avg)\n",
    "            X.append(posNegArray)\n",
    "            count += 1\n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# here we actually start evaluating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "'''turn our dataframe into dictionary format'''\n",
    "sentimentTweetDict = dfDM.to_dict(orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kNN score: 0.5981019154547034\n",
      "SVM score: 0.6482858812197009\n",
      "Logistic regression score: 0.6493596728093862\n",
      "Decision tree score: 0.6369479053168475\n"
     ]
    }
   ],
   "source": [
    "'''evaluate model, vectors generated by edgeSimilarity function. \n",
    "   Model evaluated using kNN, SVM, logistic regression, and decision tree.'''\n",
    "X, y = generateWordGraphVectors(sentimentTweetDict, posWordGraph, negWordGraph, \"edge\")\n",
    "testDict = dfTest.to_dict(orient='index')\n",
    "Xtest, ytest = generateWordGraphVectors(testDict, posWordGraph, negWordGraph, \"edge\")\n",
    "\n",
    "\n",
    "model = kNN(n_neighbors = 5)\n",
    "model.fit(X, y)\n",
    "print(\"kNN score: \" + str(model.score(Xtest, ytest)))\n",
    "\n",
    "classifier = svm.SVC(kernel = \"linear\")\n",
    "classifier.fit(X, y)\n",
    "print(\"SVM score: \" + str(classifier.score(Xtest, ytest)))\n",
    "\n",
    "classifier = logreg()\n",
    "classifier.fit(X, y)\n",
    "print(\"Logistic regression score: \" + str(classifier.score(Xtest, ytest)))\n",
    "\n",
    "classifier = dectree()\n",
    "classifier.fit(X, y)\n",
    "print(\"Decision tree score: \" + str(classifier.score(Xtest, ytest)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kNN score: 0.5575662829440838\n",
      "SVM score: 0.5854217000647434\n",
      "Logistic regression score: 0.5944541822603313\n",
      "Decision tree score: 0.5918012853916971\n"
     ]
    }
   ],
   "source": [
    "'''identical as above, except vectors generated by MCSNS'''\n",
    "X, y = generateWordGraphVectors(sentimentTweetDict, posWordGraph, negWordGraph, \"MCSNS\")\n",
    "testDict = dfTest.to_dict(orient='index')\n",
    "Xtest, ytest = generateWordGraphVectors(testDict, posWordGraph, negWordGraph, \"MCSNS\")\n",
    "\n",
    "model = kNN(n_neighbors = 5)\n",
    "model.fit(X, y)\n",
    "print(\"kNN score: \" + str(model.score(Xtest, ytest)))\n",
    "\n",
    "classifier = svm.SVC(kernel = \"linear\")\n",
    "classifier.fit(X, y)\n",
    "print(\"SVM score: \" + str(classifier.score(Xtest, ytest)))\n",
    "\n",
    "classifier = logreg()\n",
    "classifier.fit(X, y)\n",
    "print(\"Logistic regression score: \" + str(classifier.score(Xtest, ytest)))\n",
    "\n",
    "classifier = dectree()\n",
    "classifier.fit(X, y)\n",
    "print(\"Decision tree score: \" + str(classifier.score(Xtest, ytest)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kNN score: 0.5914065090719598\n",
      "SVM score: 0.6221358978003063\n",
      "Logistic regression score: 0.627125870481785\n",
      "Decision tree score: 0.6181091793389866\n"
     ]
    }
   ],
   "source": [
    "'''identical as above, except vectors generated by MCSUES'''\n",
    "X, y = generateWordGraphVectors(sentimentTweetDict, posWordGraph, negWordGraph, \"MCSUES\")\n",
    "testDict = dfTest.to_dict(orient='index')\n",
    "Xtest, ytest = generateWordGraphVectors(testDict, posWordGraph, negWordGraph, \"MCSUES\")\n",
    "\n",
    "model = kNN(n_neighbors = 5)\n",
    "model.fit(X, y)\n",
    "print(\"kNN score: \" + str(model.score(Xtest, ytest)))\n",
    "\n",
    "classifier = svm.SVC(kernel = \"linear\")\n",
    "classifier.fit(X, y)\n",
    "print(\"SVM score: \" + str(classifier.score(Xtest, ytest)))\n",
    "\n",
    "classifier = logreg()\n",
    "classifier.fit(X, y)\n",
    "print(\"Logistic regression score: \" + str(classifier.score(Xtest, ytest)))\n",
    "\n",
    "classifier = dectree()\n",
    "classifier.fit(X, y)\n",
    "print(\"Decision tree score: \" + str(classifier.score(Xtest, ytest)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kNN score: 0.5914065090719598\n",
      "SVM score: 0.6221358978003063\n",
      "Logistic regression score: 0.627125870481785\n",
      "Decision tree score: 0.618124970391776\n"
     ]
    }
   ],
   "source": [
    "'''identical as above, except vectors generated by MCSDES'''\n",
    "X, y = generateWordGraphVectors(sentimentTweetDict, posWordGraph, negWordGraph, \"MCSDES\")\n",
    "testDict = dfTest.to_dict(orient='index')\n",
    "Xtest, ytest = generateWordGraphVectors(testDict, posWordGraph, negWordGraph, \"MCSDES\")\n",
    "\n",
    "model = kNN(n_neighbors = 5)\n",
    "model.fit(X, y)\n",
    "print(\"kNN score: \" + str(model.score(Xtest, ytest)))\n",
    "\n",
    "classifier = svm.SVC(kernel = \"linear\")\n",
    "classifier.fit(X, y)\n",
    "print(\"SVM score: \" + str(classifier.score(Xtest, ytest)))\n",
    "\n",
    "classifier = logreg()\n",
    "classifier.fit(X, y)\n",
    "print(\"Logistic regression score: \" + str(classifier.score(Xtest, ytest)))\n",
    "\n",
    "classifier = dectree()\n",
    "classifier.fit(X, y)\n",
    "print(\"Decision tree score: \" + str(classifier.score(Xtest, ytest)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# here we start considering edge weights. \n",
    "weights = how many times the edge appeared."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "'''remove edges that have under a certain weight, also remove isolated \n",
    "nodes after we run this function.'''\n",
    "def removeEdgesByWeight(graph, threshold):\n",
    "    returnGraph = graph.copy()\n",
    "    edgeCountDict = nx.get_edge_attributes(returnGraph, 'weight')\n",
    "    for key, value in edgeCountDict.items():\n",
    "        if value <= threshold:\n",
    "            returnGraph.remove_edge(*key)\n",
    "    emptyNodes = list(nx.isolates(returnGraph))\n",
    "    returnGraph.remove_nodes_from(emptyNodes)\n",
    "    return returnGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "'''trim edges'''\n",
    "posWordGraphTrimmed = removeEdgesByWeight(posWordGraph, 1)\n",
    "negWordGraphTrimmed = removeEdgesByWeight(negWordGraph, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kNN score: 0.6188513588200926\n",
      "SVM score: 0.6558182134002873\n",
      "Logistic regression score: 0.6563235270895511\n",
      "Decision tree score: 0.6477805675304372\n"
     ]
    }
   ],
   "source": [
    "'''evaluate, same as above, but with new \"trimmed\" graphs, using edge similarity'''\n",
    "X, y = generateWordGraphVectors(sentimentTweetDict, posWordGraphTrimmed, negWordGraphTrimmed, \"edge\")\n",
    "testDict = dfTest.to_dict(orient='index')\n",
    "Xtest, ytest = generateWordGraphVectors(testDict, posWordGraphTrimmed, negWordGraphTrimmed, \"edge\")\n",
    "\n",
    "model = kNN(n_neighbors = 5)\n",
    "model.fit(X, y)\n",
    "print(\"kNN score: \" + str(model.score(Xtest, ytest)))\n",
    "\n",
    "classifier = svm.SVC(kernel = \"linear\")\n",
    "classifier.fit(X, y)\n",
    "print(\"SVM score: \" + str(classifier.score(Xtest, ytest)))\n",
    "\n",
    "classifier = logreg()\n",
    "classifier.fit(X, y)\n",
    "print(\"Logistic regression score: \" + str(classifier.score(Xtest, ytest)))\n",
    "\n",
    "classifier = dectree()\n",
    "classifier.fit(X, y)\n",
    "print(\"Decision tree score: \" + str(classifier.score(Xtest, ytest)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kNN score: 0.5586558655865587\n",
      "SVM score: 0.5980071691379665\n",
      "Logistic regression score: 0.6055868744769214\n",
      "Decision tree score: 0.6054763371073949\n"
     ]
    }
   ],
   "source": [
    "'''evaluate, same as above, but with new \"trimmed\" graphs, using MCSNS'''\n",
    "X, y = generateWordGraphVectors(sentimentTweetDict, posWordGraphTrimmed, negWordGraphTrimmed, \"MCSNS\")\n",
    "testDict = dfTest.to_dict(orient='index')\n",
    "Xtest, ytest = generateWordGraphVectors(testDict, posWordGraphTrimmed, negWordGraphTrimmed, \"MCSNS\")\n",
    "\n",
    "model = kNN(n_neighbors = 5)\n",
    "model.fit(X, y)\n",
    "print(\"kNN score: \" + str(model.score(Xtest, ytest)))\n",
    "\n",
    "classifier = svm.SVC(kernel = \"linear\")\n",
    "classifier.fit(X, y)\n",
    "print(\"SVM score: \" + str(classifier.score(Xtest, ytest)))\n",
    "\n",
    "classifier = logreg()\n",
    "classifier.fit(X, y)\n",
    "print(\"Logistic regression score: \" + str(classifier.score(Xtest, ytest)))\n",
    "\n",
    "classifier = dectree()\n",
    "classifier.fit(X, y)\n",
    "print(\"Decision tree score: \" + str(classifier.score(Xtest, ytest)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kNN score: 0.5729467683610466\n",
      "SVM score: 0.6287839310246814\n",
      "Logistic regression score: 0.6340107694980024\n",
      "Decision tree score: 0.6243624362436243\n"
     ]
    }
   ],
   "source": [
    "'''evaluate, same as above, but with new \"trimmed\" graphs, using MCSUES'''\n",
    "X, y = generateWordGraphVectors(sentimentTweetDict, posWordGraphTrimmed, negWordGraphTrimmed, \"MCSUES\")\n",
    "testDict = dfTest.to_dict(orient='index')\n",
    "Xtest, ytest = generateWordGraphVectors(testDict, posWordGraphTrimmed, negWordGraphTrimmed, \"MCSUES\")\n",
    "\n",
    "model = kNN(n_neighbors = 5)\n",
    "model.fit(X, y)\n",
    "print(\"kNN score: \" + str(model.score(Xtest, ytest)))\n",
    "\n",
    "classifier = svm.SVC(kernel = \"linear\")\n",
    "classifier.fit(X, y)\n",
    "print(\"SVM score: \" + str(classifier.score(Xtest, ytest)))\n",
    "\n",
    "classifier = logreg()\n",
    "classifier.fit(X, y)\n",
    "print(\"Logistic regression score: \" + str(classifier.score(Xtest, ytest)))\n",
    "\n",
    "classifier = dectree()\n",
    "classifier.fit(X, y)\n",
    "print(\"Decision tree score: \" + str(classifier.score(Xtest, ytest)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kNN score: 0.5729467683610466\n",
      "SVM score: 0.6287839310246814\n",
      "Logistic regression score: 0.6340107694980024\n",
      "Decision tree score: 0.6243150630852559\n"
     ]
    }
   ],
   "source": [
    "'''evaluate, same as above, but with new \"trimmed\" graphs, using MCSDES'''\n",
    "X, y = generateWordGraphVectors(sentimentTweetDict, posWordGraphTrimmed, negWordGraphTrimmed, \"MCSDES\")\n",
    "testDict = dfTest.to_dict(orient='index')\n",
    "Xtest, ytest = generateWordGraphVectors(testDict, posWordGraphTrimmed, negWordGraphTrimmed, \"MCSDES\")\n",
    "\n",
    "model = kNN(n_neighbors = 5)\n",
    "model.fit(X, y)\n",
    "print(\"kNN score: \" + str(model.score(Xtest, ytest)))\n",
    "\n",
    "classifier = svm.SVC(kernel = \"linear\")\n",
    "classifier.fit(X, y)\n",
    "print(\"SVM score: \" + str(classifier.score(Xtest, ytest)))\n",
    "\n",
    "classifier = logreg()\n",
    "classifier.fit(X, y)\n",
    "print(\"Logistic regression score: \" + str(classifier.score(Xtest, ytest)))\n",
    "\n",
    "classifier = dectree()\n",
    "classifier.fit(X, y)\n",
    "print(\"Decision tree score: \" + str(classifier.score(Xtest, ytest)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# adjust threshold of where to trim graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "'''trim edges'''\n",
    "posWordGraphTrimmed = removeEdgesByWeight(posWordGraph, 5)\n",
    "negWordGraphTrimmed = removeEdgesByWeight(negWordGraph, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kNN score: 0.6051131428932367\n",
      "SVM score: 0.6325579926413694\n",
      "Logistic regression score: 0.6341055158147394\n",
      "Decision tree score: 0.6284365278633126\n"
     ]
    }
   ],
   "source": [
    "'''evaluate, same as above, but with new \"trimmed\" graphs, using edge similarity'''\n",
    "X, y = generateWordGraphVectors(sentimentTweetDict, posWordGraphTrimmed, negWordGraphTrimmed, \"edge\")\n",
    "testDict = dfTest.to_dict(orient='index')\n",
    "Xtest, ytest = generateWordGraphVectors(testDict, posWordGraphTrimmed, negWordGraphTrimmed, \"edge\")\n",
    "\n",
    "model = kNN(n_neighbors = 5)\n",
    "model.fit(X, y)\n",
    "print(\"kNN score: \" + str(model.score(Xtest, ytest)))\n",
    "\n",
    "classifier = svm.SVC(kernel = \"linear\")\n",
    "classifier.fit(X, y)\n",
    "print(\"SVM score: \" + str(classifier.score(Xtest, ytest)))\n",
    "\n",
    "classifier = logreg()\n",
    "classifier.fit(X, y)\n",
    "print(\"Logistic regression score: \" + str(classifier.score(Xtest, ytest)))\n",
    "\n",
    "classifier = dectree()\n",
    "classifier.fit(X, y)\n",
    "print(\"Decision tree score: \" + str(classifier.score(Xtest, ytest)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kNN score: 0.591122270121749\n",
      "SVM score: 0.5987809307246514\n",
      "Logistic regression score: 0.6078134129202394\n",
      "Decision tree score: 0.6080186966065028\n"
     ]
    }
   ],
   "source": [
    "'''evaluate, same as above, but with new \"trimmed\" graphs, using MCSNS'''\n",
    "X, y = generateWordGraphVectors(sentimentTweetDict, posWordGraphTrimmed, negWordGraphTrimmed, \"MCSNS\")\n",
    "testDict = dfTest.to_dict(orient='index')\n",
    "Xtest, ytest = generateWordGraphVectors(testDict, posWordGraphTrimmed, negWordGraphTrimmed, \"MCSNS\")\n",
    "\n",
    "model = kNN(n_neighbors = 5)\n",
    "model.fit(X, y)\n",
    "print(\"kNN score: \" + str(model.score(Xtest, ytest)))\n",
    "\n",
    "classifier = svm.SVC(kernel = \"linear\")\n",
    "classifier.fit(X, y)\n",
    "print(\"SVM score: \" + str(classifier.score(Xtest, ytest)))\n",
    "\n",
    "classifier = logreg()\n",
    "classifier.fit(X, y)\n",
    "print(\"Logistic regression score: \" + str(classifier.score(Xtest, ytest)))\n",
    "\n",
    "classifier = dectree()\n",
    "classifier.fit(X, y)\n",
    "print(\"Decision tree score: \" + str(classifier.score(Xtest, ytest)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kNN score: 0.5932382711955406\n",
      "SVM score: 0.6221990620114644\n",
      "Logistic regression score: 0.6223885546449381\n",
      "Decision tree score: 0.6163879545849322\n"
     ]
    }
   ],
   "source": [
    "'''evaluate, same as above, but with new \"trimmed\" graphs, using MCSUES'''\n",
    "X, y = generateWordGraphVectors(sentimentTweetDict, posWordGraphTrimmed, negWordGraphTrimmed, \"MCSUES\")\n",
    "testDict = dfTest.to_dict(orient='index')\n",
    "Xtest, ytest = generateWordGraphVectors(testDict, posWordGraphTrimmed, negWordGraphTrimmed, \"MCSUES\")\n",
    "\n",
    "model = kNN(n_neighbors = 5)\n",
    "model.fit(X, y)\n",
    "print(\"kNN score: \" + str(model.score(Xtest, ytest)))\n",
    "\n",
    "classifier = svm.SVC(kernel = \"linear\")\n",
    "classifier.fit(X, y)\n",
    "print(\"SVM score: \" + str(classifier.score(Xtest, ytest)))\n",
    "\n",
    "classifier = logreg()\n",
    "classifier.fit(X, y)\n",
    "print(\"Logistic regression score: \" + str(classifier.score(Xtest, ytest)))\n",
    "\n",
    "classifier = dectree()\n",
    "classifier.fit(X, y)\n",
    "print(\"Decision tree score: \" + str(classifier.score(Xtest, ytest)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kNN score: 0.5932382711955406\n",
      "SVM score: 0.6221990620114644\n",
      "Logistic regression score: 0.6223885546449381\n",
      "Decision tree score: 0.6164037456377217\n"
     ]
    }
   ],
   "source": [
    "'''evaluate, same as above, but with new \"trimmed\" graphs, using MCSDES'''\n",
    "X, y = generateWordGraphVectors(sentimentTweetDict, posWordGraphTrimmed, negWordGraphTrimmed, \"MCSDES\")\n",
    "testDict = dfTest.to_dict(orient='index')\n",
    "Xtest, ytest = generateWordGraphVectors(testDict, posWordGraphTrimmed, negWordGraphTrimmed, \"MCSDES\")\n",
    "\n",
    "model = kNN(n_neighbors = 5)\n",
    "model.fit(X, y)\n",
    "print(\"kNN score: \" + str(model.score(Xtest, ytest)))\n",
    "\n",
    "classifier = svm.SVC(kernel = \"linear\")\n",
    "classifier.fit(X, y)\n",
    "print(\"SVM score: \" + str(classifier.score(Xtest, ytest)))\n",
    "\n",
    "classifier = logreg()\n",
    "classifier.fit(X, y)\n",
    "print(\"Logistic regression score: \" + str(classifier.score(Xtest, ytest)))\n",
    "\n",
    "classifier = dectree()\n",
    "classifier.fit(X, y)\n",
    "print(\"Decision tree score: \" + str(classifier.score(Xtest, ytest)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "'''trim edges'''\n",
    "posWordGraphTrimmed = removeEdgesByWeight(posWordGraph, 10)\n",
    "negWordGraphTrimmed = removeEdgesByWeight(negWordGraph, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kNN score: 0.5703570357035703\n",
      "SVM score: 0.6167669398518799\n",
      "Logistic regression score: 0.618219716708513\n",
      "Decision tree score: 0.6141140429832457\n"
     ]
    }
   ],
   "source": [
    "'''evaluate, same as above, but with new \"trimmed\" graphs, using edge similarity'''\n",
    "X, y = generateWordGraphVectors(sentimentTweetDict, posWordGraphTrimmed, negWordGraphTrimmed, \"edge\")\n",
    "testDict = dfTest.to_dict(orient='index')\n",
    "Xtest, ytest = generateWordGraphVectors(testDict, posWordGraphTrimmed, negWordGraphTrimmed, \"edge\")\n",
    "\n",
    "model = kNN(n_neighbors = 5)\n",
    "model.fit(X, y)\n",
    "print(\"kNN score: \" + str(model.score(Xtest, ytest)))\n",
    "\n",
    "classifier = svm.SVC(kernel = \"linear\")\n",
    "classifier.fit(X, y)\n",
    "print(\"SVM score: \" + str(classifier.score(Xtest, ytest)))\n",
    "\n",
    "classifier = logreg()\n",
    "classifier.fit(X, y)\n",
    "print(\"Logistic regression score: \" + str(classifier.score(Xtest, ytest)))\n",
    "\n",
    "classifier = dectree()\n",
    "classifier.fit(X, y)\n",
    "print(\"Decision tree score: \" + str(classifier.score(Xtest, ytest)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kNN score: 0.585153252167322\n",
      "SVM score: 0.5909327774882751\n",
      "Logistic regression score: 0.5954648096388586\n",
      "Decision tree score: 0.5976281838710187\n"
     ]
    }
   ],
   "source": [
    "'''evaluate, same as above, but with new \"trimmed\" graphs, using MCSNS'''\n",
    "X, y = generateWordGraphVectors(sentimentTweetDict, posWordGraphTrimmed, negWordGraphTrimmed, \"MCSNS\")\n",
    "testDict = dfTest.to_dict(orient='index')\n",
    "Xtest, ytest = generateWordGraphVectors(testDict, posWordGraphTrimmed, negWordGraphTrimmed, \"MCSNS\")\n",
    "\n",
    "model = kNN(n_neighbors = 5)\n",
    "model.fit(X, y)\n",
    "print(\"kNN score: \" + str(model.score(Xtest, ytest)))\n",
    "\n",
    "classifier = svm.SVC(kernel = \"linear\")\n",
    "classifier.fit(X, y)\n",
    "print(\"SVM score: \" + str(classifier.score(Xtest, ytest)))\n",
    "\n",
    "classifier = logreg()\n",
    "classifier.fit(X, y)\n",
    "print(\"Logistic regression score: \" + str(classifier.score(Xtest, ytest)))\n",
    "\n",
    "classifier = dectree()\n",
    "classifier.fit(X, y)\n",
    "print(\"Decision tree score: \" + str(classifier.score(Xtest, ytest)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kNN score: 0.5807159663334754\n",
      "SVM score: 0.6064553823803432\n",
      "Logistic regression score: 0.6066922481721856\n",
      "Decision tree score: 0.6032655897168664\n"
     ]
    }
   ],
   "source": [
    "'''evaluate, same as above, but with new \"trimmed\" graphs, using MCSUES'''\n",
    "X, y = generateWordGraphVectors(sentimentTweetDict, posWordGraphTrimmed, negWordGraphTrimmed, \"MCSUES\")\n",
    "testDict = dfTest.to_dict(orient='index')\n",
    "Xtest, ytest = generateWordGraphVectors(testDict, posWordGraphTrimmed, negWordGraphTrimmed, \"MCSUES\")\n",
    "\n",
    "model = kNN(n_neighbors = 5)\n",
    "model.fit(X, y)\n",
    "print(\"kNN score: \" + str(model.score(Xtest, ytest)))\n",
    "\n",
    "classifier = svm.SVC(kernel = \"linear\")\n",
    "classifier.fit(X, y)\n",
    "print(\"SVM score: \" + str(classifier.score(Xtest, ytest)))\n",
    "\n",
    "classifier = logreg()\n",
    "classifier.fit(X, y)\n",
    "print(\"Logistic regression score: \" + str(classifier.score(Xtest, ytest)))\n",
    "\n",
    "classifier = dectree()\n",
    "classifier.fit(X, y)\n",
    "print(\"Decision tree score: \" + str(classifier.score(Xtest, ytest)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kNN score: 0.5807159663334754\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-1748db8473ec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mclassifier\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msvm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSVC\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkernel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"linear\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"SVM score: \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXtest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mytest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\svm\\base.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    185\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    186\u001b[0m         \u001b[0mseed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrnd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'i'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 187\u001b[1;33m         \u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    188\u001b[0m         \u001b[1;31m# see comment on the other call to np.iinfo in this file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    189\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\svm\\base.py\u001b[0m in \u001b[0;36m_dense_fit\u001b[1;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[0;32m    252\u001b[0m                 \u001b[0mcache_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcache_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcoef0\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoef0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    253\u001b[0m                 \u001b[0mgamma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_gamma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 254\u001b[1;33m                 max_iter=self.max_iter, random_seed=random_seed)\n\u001b[0m\u001b[0;32m    255\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_warn_from_fit_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "'''evaluate, same as above, but with new \"trimmed\" graphs, using MCSDES'''\n",
    "X, y = generateWordGraphVectors(sentimentTweetDict, posWordGraphTrimmed, negWordGraphTrimmed, \"MCSDES\")\n",
    "testDict = dfTest.to_dict(orient='index')\n",
    "Xtest, ytest = generateWordGraphVectors(testDict, posWordGraphTrimmed, negWordGraphTrimmed, \"MCSDES\")\n",
    "\n",
    "model = kNN(n_neighbors = 5)\n",
    "model.fit(X, y)\n",
    "print(\"kNN score: \" + str(model.score(Xtest, ytest)))\n",
    "\n",
    "classifier = svm.SVC(kernel = \"linear\")\n",
    "classifier.fit(X, y)\n",
    "print(\"SVM score: \" + str(classifier.score(Xtest, ytest)))\n",
    "\n",
    "classifier = logreg()\n",
    "classifier.fit(X, y)\n",
    "print(\"Logistic regression score: \" + str(classifier.score(Xtest, ytest)))\n",
    "\n",
    "classifier = dectree()\n",
    "classifier.fit(X, y)\n",
    "print(\"Decision tree score: \" + str(classifier.score(Xtest, ytest)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# evaluate tf-idf models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''trim edges'''\n",
    "posWordGraphTrimmed = removeEdgesByWeight(posWordGraph, 1)\n",
    "negWordGraphTrimmed = removeEdgesByWeight(negWordGraph, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "'''evaluate, same as above, but with new \"trimmed\" graphs, using MCSDES'''\n",
    "X, y = generateWordGraphVectors(sentimentTweetDict, posWordGraphTrimmed, negWordGraphTrimmed, \"TFIDF_max\")\n",
    "testDict = dfTest.to_dict(orient='index')\n",
    "Xtest, ytest = generateWordGraphVectors(testDict, posWordGraphTrimmed, negWordGraphTrimmed, \"TFIDF_max\")\n",
    "\n",
    "model = kNN(n_neighbors = 5)\n",
    "model.fit(X, y)\n",
    "print(\"kNN score: \" + str(model.score(Xtest, ytest)))\n",
    "\n",
    "classifier = svm.SVC(kernel = \"linear\")\n",
    "classifier.fit(X, y)\n",
    "print(\"SVM score: \" + str(classifier.score(Xtest, ytest)))\n",
    "\n",
    "classifier = logreg()\n",
    "classifier.fit(X, y)\n",
    "print(\"Logistic regression score: \" + str(classifier.score(Xtest, ytest)))\n",
    "\n",
    "classifier = dectree()\n",
    "classifier.fit(X, y)\n",
    "print(\"Decision tree score: \" + str(classifier.score(Xtest, ytest)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "'''evaluate, same as above, but with new \"trimmed\" graphs, using MCSDES'''\n",
    "X, y = generateWordGraphVectors(sentimentTweetDict, posWordGraphTrimmed, negWordGraphTrimmed, \"TFIDF_avg\")\n",
    "testDict = dfTest.to_dict(orient='index')\n",
    "Xtest, ytest = generateWordGraphVectors(testDict, posWordGraphTrimmed, negWordGraphTrimmed, \"TFIDF_avg\")\n",
    "\n",
    "model = kNN(n_neighbors = 5)\n",
    "model.fit(X, y)\n",
    "print(\"kNN score: \" + str(model.score(Xtest, ytest)))\n",
    "\n",
    "classifier = svm.SVC(kernel = \"linear\")\n",
    "classifier.fit(X, y)\n",
    "print(\"SVM score: \" + str(classifier.score(Xtest, ytest)))\n",
    "\n",
    "classifier = logreg()\n",
    "classifier.fit(X, y)\n",
    "print(\"Logistic regression score: \" + str(classifier.score(Xtest, ytest)))\n",
    "\n",
    "classifier = dectree()\n",
    "classifier.fit(X, y)\n",
    "print(\"Decision tree score: \" + str(classifier.score(Xtest, ytest)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "'''evaluate, same as above, but with new \"trimmed\" graphs, using MCSDES'''\n",
    "X, y = generateWordGraphVectors(sentimentTweetDict, posWordGraphTrimmed, negWordGraphTrimmed, \"TFIDF_2\")\n",
    "testDict = dfTest.to_dict(orient='index')\n",
    "Xtest, ytest = generateWordGraphVectors(testDict, posWordGraphTrimmed, negWordGraphTrimmed, \"TFIDF_2\")\n",
    "\n",
    "model = kNN(n_neighbors = 5)\n",
    "model.fit(X, y)\n",
    "print(\"kNN score: \" + str(model.score(Xtest, ytest)))\n",
    "\n",
    "classifier = svm.SVC(kernel = \"linear\")\n",
    "classifier.fit(X, y)\n",
    "print(\"SVM score: \" + str(classifier.score(Xtest, ytest)))\n",
    "\n",
    "classifier = logreg()\n",
    "classifier.fit(X, y)\n",
    "print(\"Logistic regression score: \" + str(classifier.score(Xtest, ytest)))\n",
    "\n",
    "classifier = dectree()\n",
    "classifier.fit(X, y)\n",
    "print(\"Decision tree score: \" + str(classifier.score(Xtest, ytest)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
