{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Harrison\n",
      "[nltk_data]     Lu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from io import StringIO\n",
    "import networkx as nx\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize \n",
    "stop_words = set(stopwords.words('english')) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# explore data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>ID</th>\n",
       "      <th>date</th>\n",
       "      <th>query</th>\n",
       "      <th>username</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810369</td>\n",
       "      <td>mon apr 06 22:19:45 pdt 2009</td>\n",
       "      <td>no_query</td>\n",
       "      <td>_thespecialone_</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>mon apr 06 22:19:49 pdt 2009</td>\n",
       "      <td>no_query</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>mon apr 06 22:19:53 pdt 2009</td>\n",
       "      <td>no_query</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@kenichan i dived many times for the ball. man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>mon apr 06 22:19:57 pdt 2009</td>\n",
       "      <td>no_query</td>\n",
       "      <td>ellectf</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>mon apr 06 22:19:57 pdt 2009</td>\n",
       "      <td>no_query</td>\n",
       "      <td>karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment          ID                          date     query  \\\n",
       "0          0  1467810369  mon apr 06 22:19:45 pdt 2009  no_query   \n",
       "1          0  1467810672  mon apr 06 22:19:49 pdt 2009  no_query   \n",
       "2          0  1467810917  mon apr 06 22:19:53 pdt 2009  no_query   \n",
       "3          0  1467811184  mon apr 06 22:19:57 pdt 2009  no_query   \n",
       "4          0  1467811193  mon apr 06 22:19:57 pdt 2009  no_query   \n",
       "\n",
       "          username                                               text  \n",
       "0  _thespecialone_  @switchfoot http://twitpic.com/2y1zl - awww, t...  \n",
       "1    scotthamilton  is upset that he can't update his facebook by ...  \n",
       "2         mattycus  @kenichan i dived many times for the ball. man...  \n",
       "3          ellectf    my whole body feels itchy and like its on fire   \n",
       "4           karoli  @nationwideclass no, it's not behaving at all....  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./dataset/sentiment140/data.csv', encoding='latin-1', header = None)\n",
    "df.columns = ['sentiment', 'ID', 'date', 'query', 'username', 'text']\n",
    "\n",
    "df = df.applymap(lambda s: s.lower() if type(s) == str else s)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# splitting entire dataset\n",
    "\n",
    "not used in experiment below yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfTrain = df.sample(frac = 0.8, random_state = 20)\n",
    "dfTest = df.drop(dfTrain.index)\n",
    "\n",
    "dfGraphModel = dfTrain.sample(frac = 0.5, random_state = 20)\n",
    "dfDM = dfTrain.drop(dfGraphModel.index)\n",
    "\n",
    "#subset of the dfTrain dataset, split into positive, negative, and neutral tweets\n",
    "pos = dfGraphModel.loc[df['sentiment'] == 4]\n",
    "neg = dfGraphModel.loc[df['sentiment'] == 0]\n",
    "neut = dfGraphModel.loc[df['sentiment'] == 2]\n",
    "\n",
    "posText = {line[\"ID\"]: line[\"text\"] for index, line in pos.iterrows()}\n",
    "negText = {line[\"ID\"]: line[\"text\"] for index, line in neg.iterrows()}\n",
    "\n",
    "posWords = [line.rstrip('\\n') for line in open('./dataset/positive-words.txt') if line.split() and list(line)[0] != ';']\n",
    "negWords = [line.rstrip('\\n') for line in open('./dataset/negative-words.txt') if line.split() and list(line)[0] != \";\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# filtering by target word \"food\"\n",
    "result in 4000 something tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>query</th>\n",
       "      <th>username</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1598507</th>\n",
       "      <td>4</td>\n",
       "      <td>2193188422</td>\n",
       "      <td>tue jun 16 08:06:59 pdt 2009</td>\n",
       "      <td>no_query</td>\n",
       "      <td>melisarenea</td>\n",
       "      <td>ughh hate wake early drink...aren't supposed s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1598732</th>\n",
       "      <td>4</td>\n",
       "      <td>2193255029</td>\n",
       "      <td>tue jun 16 08:12:27 pdt 2009</td>\n",
       "      <td>no_query</td>\n",
       "      <td>jessie2point0</td>\n",
       "      <td>needs food iphone?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599079</th>\n",
       "      <td>4</td>\n",
       "      <td>2193344265</td>\n",
       "      <td>tue jun 16 08:19:50 pdt 2009</td>\n",
       "      <td>no_query</td>\n",
       "      <td>sanityknit</td>\n",
       "      <td>text tell things going! miss guys!! fun - nice...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599611</th>\n",
       "      <td>4</td>\n",
       "      <td>2193478364</td>\n",
       "      <td>tue jun 16 08:30:46 pdt 2009</td>\n",
       "      <td>no_query</td>\n",
       "      <td>kirstylol</td>\n",
       "      <td>needs food soo much. going watch t.v shower la...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599831</th>\n",
       "      <td>4</td>\n",
       "      <td>2193551690</td>\n",
       "      <td>tue jun 16 08:36:43 pdt 2009</td>\n",
       "      <td>no_query</td>\n",
       "      <td>exbp_buddhist</td>\n",
       "      <td>could born emporer penguin. minus 200, carryin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         sentiment          id                          date     query  \\\n",
       "1598507          4  2193188422  tue jun 16 08:06:59 pdt 2009  no_query   \n",
       "1598732          4  2193255029  tue jun 16 08:12:27 pdt 2009  no_query   \n",
       "1599079          4  2193344265  tue jun 16 08:19:50 pdt 2009  no_query   \n",
       "1599611          4  2193478364  tue jun 16 08:30:46 pdt 2009  no_query   \n",
       "1599831          4  2193551690  tue jun 16 08:36:43 pdt 2009  no_query   \n",
       "\n",
       "              username                                              tweet  \n",
       "1598507    melisarenea  ughh hate wake early drink...aren't supposed s...  \n",
       "1598732  jessie2point0                                 needs food iphone?  \n",
       "1599079     sanityknit  text tell things going! miss guys!! fun - nice...  \n",
       "1599611      kirstylol  needs food soo much. going watch t.v shower la...  \n",
       "1599831  exbp_buddhist  could born emporer penguin. minus 200, carryin...  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subjectTweetsDict = {} # key = index in original df and value = tweet info (sentiment, id, date, query, username, full tweet)\n",
    "filteredTweets = {} # key = index in original df and value = filtered tweet\n",
    "count = 0\n",
    "for row in df.itertuples():\n",
    "    if 'food' in row[6]:\n",
    "        subjectTweetsDict[row[0]] = list(row)[1:7]\n",
    "        word_tokens = str(row[6]).split() #split by white space\n",
    "        filtered_sentence = [w for w in word_tokens if not w in stop_words] \n",
    "        filtered_sentence = [] \n",
    "        i = 0\n",
    "        while i < len(word_tokens):\n",
    "            if '@' in word_tokens[i]: #Taking out handles from tweets\n",
    "                i = i + 1\n",
    "            elif word_tokens[i] not in stop_words:\n",
    "                filtered_sentence.append(word_tokens[i])\n",
    "            i = i + 1\n",
    "        filteredTweets[row[0]] = filtered_sentence\n",
    "#print(subjectTweetsDict)\n",
    "#df2 = pd.DataFrame(data=subjectTweetsDict, columns = ['index', 'sentiment', 'id', 'date', 'query', 'username', 'tweet'])\n",
    "dfSubject= pd.DataFrame.from_dict(subjectTweetsDict, orient = 'index', columns = ['sentiment', 'id', 'date', 'query', 'username', 'tweet'])\n",
    "for key, value in filteredTweets.items():\n",
    "    filteredString = ' '.join(value)\n",
    "    dfSubject.at[key, \"tweet\"] = filteredString\n",
    "\n",
    "dfSubject.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## splitting our dataset into training, testing set.\n",
    "split training into creating graph model, as well as creating the data mining model. \n",
    "split graph model into positive, negative, and neutral.\n",
    "\n",
    "no neutral tweets, as we have found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfTrain = dfSubject.sample(frac = 0.8, random_state = 20)\n",
    "dfTest = dfSubject.drop(dfTrain.index)\n",
    "\n",
    "dfGraphModel = dfTrain.sample(frac = 0.6, random_state = 20)\n",
    "dfDM = dfTrain.drop(dfGraphModel.index)\n",
    "\n",
    "posSubject = dfGraphModel.loc[dfSubject['sentiment'] == 4]\n",
    "negSubject = dfGraphModel.loc[dfSubject['sentiment'] == 0]\n",
    "neutSubject = dfGraphModel.loc[dfSubject['sentiment'] == 2] #there is no neutral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def createGraph(text, wordGraph, frame):\n",
    "#     if text:\n",
    "#         text = re.sub(r'[^\\w\\s]', '', str(text))\n",
    "#         text = text.split()\n",
    "#         try:\n",
    "#             for x in range(len(text) - frame):\n",
    "#                 for y in range(1, frame + 1):\n",
    "#                     wordGraph.add_edge(text[x], text[x+y])\n",
    "#             for x in reversed(range(1, frame + 1)):\n",
    "#                 for y in reversed(range(1, x)):\n",
    "#                     wordGraph.add_edge(text[len(text) - x], text[len(text) - y])\n",
    "#         except IndexError:\n",
    "#             return createGraph(text, wordGraph, frame-1)\n",
    "#         return wordGraph\n",
    "#     else:\n",
    "#         return wordGraph\n",
    "    \n",
    "# def createGraphFromTweet(text, frame):\n",
    "#     wordGraph = nx.DiGraph()\n",
    "#     if type(text) == str:\n",
    "#         createGraph(text, wordGraph, frame)\n",
    "#     if type(text) == list:\n",
    "#         for element in text:\n",
    "#             createGraph(element, wordGraph, frame)\n",
    "#     return wordGraph\n",
    "\n",
    "def createGraph(text, wordGraph, frame):\n",
    "    if text:\n",
    "        text = re.sub(r'[^\\w\\s]', '', str(text))\n",
    "        text = text.split()\n",
    "        try:\n",
    "            if len(text) == 1:\n",
    "                wordGraph.add_edge(text[0], text[0], weight = 1)\n",
    "            for x in range(len(text) - frame):\n",
    "                for y in range(1, frame + 1):\n",
    "                    n1 = text[x]\n",
    "                    n2 = text[x+y]\n",
    "                    if wordGraph.has_edge(n1, n2):\n",
    "                        wordGraph[n1][n2]['weight'] = wordGraph[n1][n2]['weight'] + 1\n",
    "                    else:\n",
    "                        wordGraph.add_edge(n1, n2, weight = 1)\n",
    "            for x in reversed(range(1, frame + 1)):\n",
    "                for y in reversed(range(1, x)):\n",
    "                    n1 = text[len(text) - x]\n",
    "                    n2 = text[len(text) - y]\n",
    "                    if wordGraph.has_edge(n1, n2):\n",
    "                        wordGraph[n1][n2]['weight'] = wordGraph[n1][n2]['weight'] + 1\n",
    "                    else:\n",
    "                        wordGraph.add_edge(n1, n2, weight = 1)\n",
    "        except IndexError:\n",
    "            return createGraph(text, wordGraph, frame-1)\n",
    "        return wordGraph\n",
    "    else:\n",
    "        return wordGraph\n",
    "    \n",
    "def createGraphFromTweet(text, frame):\n",
    "    wordGraph = nx.DiGraph()\n",
    "    if type(text) == str:\n",
    "        createGraphWithWeight(text, wordGraph, frame)\n",
    "    if type(text) == list:\n",
    "        for element in text:\n",
    "            createGraphWithWeight(element, wordGraph, frame)\n",
    "    return wordGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Harrison Lu\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\Users\\Harrison Lu\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py:2: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "posArrayText = posSubject.as_matrix(columns = posSubject.columns[-1:]).flatten().tolist()\n",
    "negArrayText = negSubject.as_matrix(columns = negSubject.columns[-1:]).flatten().tolist()\n",
    "posWordGraph = createGraphFromTweet(posArrayText, 4)\n",
    "negWordGraph = createGraphFromTweet(negArrayText, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#graph similary functions\n",
    "\n",
    "def edgeSimilarity(inputGraph, model):\n",
    "    count = 0\n",
    "    for edge in inputGraph.edges():\n",
    "        n1, n2 = edge\n",
    "        if model.has_edge(n1, n2): \n",
    "            count += 1\n",
    "    return count/min(len(inputGraph), len(model))\n",
    "\n",
    "def getMCS(graphModel, tweetGraph):\n",
    "    matching_graph=nx.Graph() #subgraph\n",
    "\n",
    "    for n1,n2,attr in tweetGraph.edges(data=True):\n",
    "        if graphModel.has_edge(n1,n2) :\n",
    "            matching_graph.add_edge(n1,n2,weight=1)\n",
    "\n",
    "    graphs = list(nx.connected_component_subgraphs(matching_graph))\n",
    "\n",
    "    mcs_length = 0\n",
    "    mcs_graph = nx.DiGraph() \n",
    "    \n",
    "    for i, graph in enumerate(graphs):                        #Finding maximum subgraph out of all graphs\n",
    "\n",
    "        if len(graph.nodes()) > mcs_length: \n",
    "            mcs_length = len(graph.nodes())\n",
    "            mcs_graph = graph\n",
    "\n",
    "    return mcs_graph\n",
    "\n",
    "def MCSNS(mcs_graph, graphModel, tweetGraph): #number of nodes in common subgraph divided by minimum number of nodes\n",
    "    return len(mcs_graph)/min(len(graphModel),len(tweetGraph))\n",
    "\n",
    "def MCSUES(mcs_graph, graphModel, tweetGraph): #number of edges in MCS divided by min number of nodes\n",
    "    return len(mcs_graph.edges())/min(len(graphModel),len(tweetGraph))\n",
    "\n",
    "def MCSDES(mcs_graph, graphModel, tweetGraph): #edges in the mcs_graph are the same direction in both graphs\n",
    "    count = 0\n",
    "    for e1,e2 in mcs_graph.edges():\n",
    "        if tweetGraph.has_edge(e1,e2) and graphModel.has_edge(e1,e2):\n",
    "            count+=1\n",
    "    return count/min(len(graphModel),len(tweetGraph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sentimentTweetDict = dfDM.to_dict(orient='index')\n",
    "\n",
    "def generateWordGraphVectors(dataframeDict, posWordGraph, negWordGraph, metricType):\n",
    "    X = []\n",
    "    y = []\n",
    "    count = 0\n",
    "    for key, value in dataframeDict.items():\n",
    "        if value['tweet']:\n",
    "            y.append(value['sentiment'])\n",
    "            wordGraph = createGraphFromTweet(value['tweet'], 4)\n",
    "            posNegArray = []\n",
    "            if metricType == \"edge\":\n",
    "                posNegArray.append(edgeSimilarity(wordGraph, posWordGraph))\n",
    "                posNegArray.append(edgeSimilarity(wordGraph, negWordGraph))\n",
    "            elif metricType == \"MCSNS\":\n",
    "                mcs_graph = getMCS(posWordGraph, wordGraph)\n",
    "                posNegArray.append(MCSNS(mcs_graph, wordGraph, posWordGraph))\n",
    "                mcs_graph = getMCS(negWordGraph, wordGraph)\n",
    "                posNegArray.append(MCSNS(mcs_graph, wordGraph, negWordGraph))\n",
    "            elif metricType == \"MCSUES\":\n",
    "                mcs_graph = getMCS(posWordGraph, wordGraph)\n",
    "                posNegArray.append(MCSUES(mcs_graph, wordGraph, posWordGraph))\n",
    "                mcs_graph = getMCS(negWordGraph, wordGraph)\n",
    "                posNegArray.append(MCSUES(mcs_graph, wordGraph, negWordGraph))\n",
    "            elif metricType == \"MCSDES\":\n",
    "                mcs_graph = getMCS(posWordGraph, wordGraph)\n",
    "                posNegArray.append(MCSDES(mcs_graph, wordGraph, posWordGraph))\n",
    "                mcs_graph = getMCS(negWordGraph, wordGraph)\n",
    "                posNegArray.append(MCSDES(mcs_graph, wordGraph, negWordGraph))\n",
    "            X.append(posNegArray)\n",
    "            count += 1\n",
    "    return X, y\n",
    "\n",
    "X, y = generateWordGraphVectors(sentimentTweetDict, posWordGraph, negWordGraph, \"edge\")\n",
    "testDict = dfTest.to_dict(orient='index')\n",
    "Xtest, ytest = generateWordGraphVectors(testDict, posWordGraph, negWordGraph, \"edge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.582345971563981"
      ]
     },
     "execution_count": 500,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#try kNN method\n",
    "from sklearn.neighbors import KNeighborsClassifier as kNN\n",
    "\n",
    "\n",
    "model = kNN(n_neighbors = 5)\n",
    "model.fit(X, y)\n",
    "model.score(Xtest, ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.620260663507109"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#svm\n",
    "from sklearn import svm\n",
    "\n",
    "classifier = svm.SVC(kernel = \"linear\")\n",
    "classifier.fit(X, y)\n",
    "classifier.score(Xtest, ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.625"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#linear regression\n",
    "from sklearn.linear_model import LogisticRegression as logreg\n",
    "\n",
    "classifier = logreg()\n",
    "classifier.fit(X, y)\n",
    "classifier.score(Xtest, ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5598341232227488"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#decision tree\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier as dectree\n",
    "\n",
    "classifier = dectree()\n",
    "classifier.fit(X, y)\n",
    "classifier.score(Xtest, ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kNN score: 0.5438388625592417\n",
      "SVM score: 0.580568720379147\n",
      "Logistic regression score: 0.5817535545023697\n",
      "Decision tree score: 0.5545023696682464\n"
     ]
    }
   ],
   "source": [
    "X, y = generateWordGraphVectors(sentimentTweetDict, posWordGraph, negWordGraph, \"MCSNS\")\n",
    "testDict = dfTest.to_dict(orient='index')\n",
    "Xtest, ytest = generateWordGraphVectors(testDict, posWordGraph, negWordGraph, \"MCSNS\")\n",
    "\n",
    "model = kNN(n_neighbors = 5)\n",
    "model.fit(X, y)\n",
    "print(\"kNN score: \" + str(model.score(Xtest, ytest)))\n",
    "\n",
    "classifier = svm.SVC(kernel = \"linear\")\n",
    "classifier.fit(X, y)\n",
    "print(\"SVM score: \" + str(classifier.score(Xtest, ytest)))\n",
    "\n",
    "classifier = logreg()\n",
    "classifier.fit(X, y)\n",
    "print(\"Logistic regression score: \" + str(classifier.score(Xtest, ytest)))\n",
    "\n",
    "classifier = dectree()\n",
    "classifier.fit(X, y)\n",
    "print(\"Decision tree score: \" + str(classifier.score(Xtest, ytest)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kNN score: 0.5989336492890995\n",
      "SVM score: 0.6149289099526066\n",
      "Logistic regression score: 0.6137440758293838\n",
      "Decision tree score: 0.5610189573459715\n"
     ]
    }
   ],
   "source": [
    "X, y = generateWordGraphVectors(sentimentTweetDict, posWordGraph, negWordGraph, \"MCSUES\")\n",
    "testDict = dfTest.to_dict(orient='index')\n",
    "Xtest, ytest = generateWordGraphVectors(testDict, posWordGraph, negWordGraph, \"MCSUES\")\n",
    "\n",
    "model = kNN(n_neighbors = 5)\n",
    "model.fit(X, y)\n",
    "print(\"kNN score: \" + str(model.score(Xtest, ytest)))\n",
    "\n",
    "classifier = svm.SVC(kernel = \"linear\")\n",
    "classifier.fit(X, y)\n",
    "print(\"SVM score: \" + str(classifier.score(Xtest, ytest)))\n",
    "\n",
    "classifier = logreg()\n",
    "classifier.fit(X, y)\n",
    "print(\"Logistic regression score: \" + str(classifier.score(Xtest, ytest)))\n",
    "\n",
    "classifier = dectree()\n",
    "classifier.fit(X, y)\n",
    "print(\"Decision tree score: \" + str(classifier.score(Xtest, ytest)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kNN score: 0.5361374407582938\n",
      "SVM score: 0.5669431279620853\n",
      "Logistic regression score: 0.5728672985781991\n",
      "Decision tree score: 0.5219194312796208\n"
     ]
    }
   ],
   "source": [
    "X, y = generateWordGraphVectors(sentimentTweetDict, posWordGraph, negWordGraph, \"MCSDES\")\n",
    "testDict = dfTest.to_dict(orient='index')\n",
    "Xtest, ytest = generateWordGraphVectors(testDict, posWordGraph, negWordGraph, \"MCSDES\")\n",
    "\n",
    "model = kNN(n_neighbors = 5)\n",
    "model.fit(X, y)\n",
    "print(\"kNN score: \" + str(model.score(Xtest, ytest)))\n",
    "\n",
    "classifier = svm.SVC(kernel = \"linear\")\n",
    "classifier.fit(X, y)\n",
    "print(\"SVM score: \" + str(classifier.score(Xtest, ytest)))\n",
    "\n",
    "classifier = logreg()\n",
    "classifier.fit(X, y)\n",
    "print(\"Logistic regression score: \" + str(classifier.score(Xtest, ytest)))\n",
    "\n",
    "classifier = dectree()\n",
    "classifier.fit(X, y)\n",
    "print(\"Decision tree score: \" + str(classifier.score(Xtest, ytest)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#trimming graphs based on a hard limit- how many times a word was used. basically, edge weight of 1 or 0\n",
    "\n",
    "def createGraphWithWeight(text, wordGraph, frame):\n",
    "    if text:\n",
    "        text = re.sub(r'[^\\w\\s]', '', str(text))\n",
    "        text = text.split()\n",
    "        try:\n",
    "            if len(text) == 1:\n",
    "                wordGraph.add_edge(text[0], text[0], weight = 1)\n",
    "            for x in range(len(text) - frame):\n",
    "                for y in range(1, frame + 1):\n",
    "                    n1 = text[x]\n",
    "                    n2 = text[x+y]\n",
    "                    if wordGraph.has_edge(n1, n2):\n",
    "                        wordGraph[n1][n2]['weight'] = wordGraph[n1][n2]['weight'] + 1\n",
    "                    else:\n",
    "                        wordGraph.add_edge(n1, n2, weight = 1)\n",
    "            for x in reversed(range(1, frame + 1)):\n",
    "                for y in reversed(range(1, x)):\n",
    "                    n1 = text[len(text) - x]\n",
    "                    n2 = text[len(text) - y]\n",
    "                    if wordGraph.has_edge(n1, n2):\n",
    "                        wordGraph[n1][n2]['weight'] = wordGraph[n1][n2]['weight'] + 1\n",
    "                    else:\n",
    "                        wordGraph.add_edge(n1, n2, weight = 1)\n",
    "        except IndexError:\n",
    "            return createGraph(text, wordGraph, frame-1)\n",
    "        return wordGraph\n",
    "    else:\n",
    "        return wordGraph\n",
    "    \n",
    "def createGraphWithWeightsFromTweet(text, frame):\n",
    "    wordGraph = nx.DiGraph()\n",
    "    if type(text) == str:\n",
    "        createGraphWithWeight(text, wordGraph, frame)\n",
    "    if type(text) == list:\n",
    "        for element in text:\n",
    "            createGraphWithWeight(element, wordGraph, frame)\n",
    "    return wordGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "posWordGraph = createGraphWithWeightsFromTweet(posArrayText, 4)\n",
    "negWordGraph = createGraphWithWeightsFromTweet(negArrayText, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def removeEdgesByWeight(graph, threshold):\n",
    "    returnGraph = graph.copy()\n",
    "    edgeCountDict = nx.get_edge_attributes(returnGraph, 'weight')\n",
    "    for key, value in edgeCountDict.items():\n",
    "        if value <= threshold:\n",
    "            returnGraph.remove_edge(*key)\n",
    "    emptyNodes = list(nx.isolates(returnGraph))\n",
    "    returnGraph.remove_nodes_from(emptyNodes)\n",
    "    return returnGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kNN score: 0.5835308056872038\n",
      "SVM score: 0.6226303317535545\n",
      "Logistic regression score: 0.6279620853080569\n",
      "Decision tree score: 0.5870853080568721\n"
     ]
    }
   ],
   "source": [
    "posWordGraphTrimmed = removeEdgesByWeight(posWordGraph, 1)\n",
    "negWordGraphTrimmed = removeEdgesByWeight(negWordGraph, 1)\n",
    "\n",
    "X, y = generateWordGraphVectors(sentimentTweetDict, posWordGraphTrimmed, negWordGraphTrimmed, \"edge\")\n",
    "testDict = dfTest.to_dict(orient='index')\n",
    "Xtest, ytest = generateWordGraphVectors(testDict, posWordGraphTrimmed, negWordGraphTrimmed, \"edge\")\n",
    "\n",
    "model = kNN(n_neighbors = 5)\n",
    "model.fit(X, y)\n",
    "print(\"kNN score: \" + str(model.score(Xtest, ytest)))\n",
    "\n",
    "classifier = svm.SVC(kernel = \"linear\")\n",
    "classifier.fit(X, y)\n",
    "print(\"SVM score: \" + str(classifier.score(Xtest, ytest)))\n",
    "\n",
    "classifier = logreg()\n",
    "classifier.fit(X, y)\n",
    "print(\"Logistic regression score: \" + str(classifier.score(Xtest, ytest)))\n",
    "\n",
    "classifier = dectree()\n",
    "classifier.fit(X, y)\n",
    "print(\"Decision tree score: \" + str(classifier.score(Xtest, ytest)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kNN score: 0.5616113744075829\n",
      "SVM score: 0.5764218009478673\n",
      "Logistic regression score: 0.5930094786729858\n",
      "Decision tree score: 0.5633886255924171\n"
     ]
    }
   ],
   "source": [
    "X, y = generateWordGraphVectors(sentimentTweetDict, posWordGraphTrimmed, negWordGraphTrimmed, \"MCSNS\")\n",
    "testDict = dfTest.to_dict(orient='index')\n",
    "Xtest, ytest = generateWordGraphVectors(testDict, posWordGraphTrimmed, negWordGraphTrimmed, \"MCSNS\")\n",
    "\n",
    "model = kNN(n_neighbors = 5)\n",
    "model.fit(X, y)\n",
    "print(\"kNN score: \" + str(model.score(Xtest, ytest)))\n",
    "\n",
    "classifier = svm.SVC(kernel = \"linear\")\n",
    "classifier.fit(X, y)\n",
    "print(\"SVM score: \" + str(classifier.score(Xtest, ytest)))\n",
    "\n",
    "classifier = logreg()\n",
    "classifier.fit(X, y)\n",
    "print(\"Logistic regression score: \" + str(classifier.score(Xtest, ytest)))\n",
    "\n",
    "classifier = dectree()\n",
    "classifier.fit(X, y)\n",
    "print(\"Decision tree score: \" + str(classifier.score(Xtest, ytest)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kNN score: 0.568127962085308\n",
      "SVM score: 0.5859004739336493\n",
      "Logistic regression score: 0.6078199052132701\n",
      "Decision tree score: 0.5503554502369669\n"
     ]
    }
   ],
   "source": [
    "X, y = generateWordGraphVectors(sentimentTweetDict, posWordGraphTrimmed, negWordGraphTrimmed, \"MCSUES\")\n",
    "testDict = dfTest.to_dict(orient='index')\n",
    "Xtest, ytest = generateWordGraphVectors(testDict, posWordGraphTrimmed, negWordGraphTrimmed, \"MCSUES\")\n",
    "\n",
    "model = kNN(n_neighbors = 5)\n",
    "model.fit(X, y)\n",
    "print(\"kNN score: \" + str(model.score(Xtest, ytest)))\n",
    "\n",
    "classifier = svm.SVC(kernel = \"linear\")\n",
    "classifier.fit(X, y)\n",
    "print(\"SVM score: \" + str(classifier.score(Xtest, ytest)))\n",
    "\n",
    "classifier = logreg()\n",
    "classifier.fit(X, y)\n",
    "print(\"Logistic regression score: \" + str(classifier.score(Xtest, ytest)))\n",
    "\n",
    "classifier = dectree()\n",
    "classifier.fit(X, y)\n",
    "print(\"Decision tree score: \" + str(classifier.score(Xtest, ytest)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kNN score: 0.5408767772511849\n",
      "SVM score: 0.5432464454976303\n",
      "Logistic regression score: 0.5627962085308057\n",
      "Decision tree score: 0.556872037914692\n"
     ]
    }
   ],
   "source": [
    "X, y = generateWordGraphVectors(sentimentTweetDict, posWordGraphTrimmed, negWordGraphTrimmed, \"MCSDES\")\n",
    "testDict = dfTest.to_dict(orient='index')\n",
    "Xtest, ytest = generateWordGraphVectors(testDict, posWordGraphTrimmed, negWordGraphTrimmed, \"MCSDES\")\n",
    "\n",
    "model = kNN(n_neighbors = 5)\n",
    "model.fit(X, y)\n",
    "print(\"kNN score: \" + str(model.score(Xtest, ytest)))\n",
    "\n",
    "classifier = svm.SVC(kernel = \"linear\")\n",
    "classifier.fit(X, y)\n",
    "print(\"SVM score: \" + str(classifier.score(Xtest, ytest)))\n",
    "\n",
    "classifier = logreg()\n",
    "classifier.fit(X, y)\n",
    "print(\"Logistic regression score: \" + str(classifier.score(Xtest, ytest)))\n",
    "\n",
    "classifier = dectree()\n",
    "classifier.fit(X, y)\n",
    "print(\"Decision tree score: \" + str(classifier.score(Xtest, ytest)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
