{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Harrison\n",
      "[nltk_data]     Lu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from io import StringIO\n",
    "import networkx as nx\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize \n",
    "stop_words = set(stopwords.words('english')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>ID</th>\n",
       "      <th>date</th>\n",
       "      <th>query</th>\n",
       "      <th>username</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810369</td>\n",
       "      <td>mon apr 06 22:19:45 pdt 2009</td>\n",
       "      <td>no_query</td>\n",
       "      <td>_thespecialone_</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>mon apr 06 22:19:49 pdt 2009</td>\n",
       "      <td>no_query</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>mon apr 06 22:19:53 pdt 2009</td>\n",
       "      <td>no_query</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@kenichan i dived many times for the ball. man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>mon apr 06 22:19:57 pdt 2009</td>\n",
       "      <td>no_query</td>\n",
       "      <td>ellectf</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>mon apr 06 22:19:57 pdt 2009</td>\n",
       "      <td>no_query</td>\n",
       "      <td>karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment          ID                          date     query  \\\n",
       "0          0  1467810369  mon apr 06 22:19:45 pdt 2009  no_query   \n",
       "1          0  1467810672  mon apr 06 22:19:49 pdt 2009  no_query   \n",
       "2          0  1467810917  mon apr 06 22:19:53 pdt 2009  no_query   \n",
       "3          0  1467811184  mon apr 06 22:19:57 pdt 2009  no_query   \n",
       "4          0  1467811193  mon apr 06 22:19:57 pdt 2009  no_query   \n",
       "\n",
       "          username                                               text  \n",
       "0  _thespecialone_  @switchfoot http://twitpic.com/2y1zl - awww, t...  \n",
       "1    scotthamilton  is upset that he can't update his facebook by ...  \n",
       "2         mattycus  @kenichan i dived many times for the ball. man...  \n",
       "3          ellectf    my whole body feels itchy and like its on fire   \n",
       "4           karoli  @nationwideclass no, it's not behaving at all....  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./dataset/sentiment140/data.csv', encoding='latin-1', header = None)\n",
    "df.columns = ['sentiment', 'ID', 'date', 'query', 'username', 'text']\n",
    "\n",
    "df = df.applymap(lambda s: s.lower() if type(s) == str else s)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfTrain = df.sample(frac = 0.8, random_state = 20)\n",
    "dfTest = df.drop(dfTrain.index)\n",
    "\n",
    "dfGraphModel = dfTrain.sample(frac = 0.5, random_state = 20)\n",
    "dfDM = dfTrain.drop(dfGraphModel.index)\n",
    "\n",
    "#subset of the dfTrain dataset, split into positive, negative, and neutral tweets\n",
    "pos = dfGraphModel.loc[df['sentiment'] == 4]\n",
    "neg = dfGraphModel.loc[df['sentiment'] == 0]\n",
    "neut = dfGraphModel.loc[df['sentiment'] == 2]\n",
    "\n",
    "posText = {line[\"ID\"]: line[\"text\"] for index, line in pos.iterrows()}\n",
    "negText = {line[\"ID\"]: line[\"text\"] for index, line in neg.iterrows()}\n",
    "\n",
    "posWords = [line.rstrip('\\n') for line in open('./dataset/positive-words.txt') if line.split() and list(line)[0] != ';']\n",
    "negWords = [line.rstrip('\\n') for line in open('./dataset/negative-words.txt') if line.split() and list(line)[0] != \";\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>query</th>\n",
       "      <th>username</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1598507</th>\n",
       "      <td>4</td>\n",
       "      <td>2193188422</td>\n",
       "      <td>tue jun 16 08:06:59 pdt 2009</td>\n",
       "      <td>no_query</td>\n",
       "      <td>melisarenea</td>\n",
       "      <td>ughh hate wake early drink...aren't supposed s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1598732</th>\n",
       "      <td>4</td>\n",
       "      <td>2193255029</td>\n",
       "      <td>tue jun 16 08:12:27 pdt 2009</td>\n",
       "      <td>no_query</td>\n",
       "      <td>jessie2point0</td>\n",
       "      <td>needs food iphone?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599079</th>\n",
       "      <td>4</td>\n",
       "      <td>2193344265</td>\n",
       "      <td>tue jun 16 08:19:50 pdt 2009</td>\n",
       "      <td>no_query</td>\n",
       "      <td>sanityknit</td>\n",
       "      <td>text tell things going! miss guys!! fun - nice...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599611</th>\n",
       "      <td>4</td>\n",
       "      <td>2193478364</td>\n",
       "      <td>tue jun 16 08:30:46 pdt 2009</td>\n",
       "      <td>no_query</td>\n",
       "      <td>kirstylol</td>\n",
       "      <td>needs food soo much. going watch t.v shower la...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599831</th>\n",
       "      <td>4</td>\n",
       "      <td>2193551690</td>\n",
       "      <td>tue jun 16 08:36:43 pdt 2009</td>\n",
       "      <td>no_query</td>\n",
       "      <td>exbp_buddhist</td>\n",
       "      <td>could born emporer penguin. minus 200, carryin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         sentiment          id                          date     query  \\\n",
       "1598507          4  2193188422  tue jun 16 08:06:59 pdt 2009  no_query   \n",
       "1598732          4  2193255029  tue jun 16 08:12:27 pdt 2009  no_query   \n",
       "1599079          4  2193344265  tue jun 16 08:19:50 pdt 2009  no_query   \n",
       "1599611          4  2193478364  tue jun 16 08:30:46 pdt 2009  no_query   \n",
       "1599831          4  2193551690  tue jun 16 08:36:43 pdt 2009  no_query   \n",
       "\n",
       "              username                                              tweet  \n",
       "1598507    melisarenea  ughh hate wake early drink...aren't supposed s...  \n",
       "1598732  jessie2point0                                 needs food iphone?  \n",
       "1599079     sanityknit  text tell things going! miss guys!! fun - nice...  \n",
       "1599611      kirstylol  needs food soo much. going watch t.v shower la...  \n",
       "1599831  exbp_buddhist  could born emporer penguin. minus 200, carryin...  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subjectTweetsDict = {} # key = index in original df and value = tweet info (sentiment, id, date, query, username, full tweet)\n",
    "filteredTweets = {} # key = index in original df and value = filtered tweet\n",
    "count = 0\n",
    "for row in df.itertuples():\n",
    "    if 'food' in row[6]:\n",
    "        subjectTweetsDict[row[0]] = list(row)[1:7]\n",
    "        word_tokens = str(row[6]).split() #split by white space\n",
    "        filtered_sentence = [w for w in word_tokens if not w in stop_words] \n",
    "        filtered_sentence = [] \n",
    "        i = 0\n",
    "        while i < len(word_tokens):\n",
    "            if '@' in word_tokens[i]: #Taking out handles from tweets\n",
    "                i = i + 1\n",
    "            elif word_tokens[i] not in stop_words:\n",
    "                filtered_sentence.append(word_tokens[i])\n",
    "            i = i + 1\n",
    "        filteredTweets[row[0]] = filtered_sentence\n",
    "#print(subjectTweetsDict)\n",
    "#df2 = pd.DataFrame(data=subjectTweetsDict, columns = ['index', 'sentiment', 'id', 'date', 'query', 'username', 'tweet'])\n",
    "dfSubject= pd.DataFrame.from_dict(subjectTweetsDict, orient = 'index', columns = ['sentiment', 'id', 'date', 'query', 'username', 'tweet'])\n",
    "for key, value in filteredTweets.items():\n",
    "    filteredString = ' '.join(value)\n",
    "    dfSubject.at[key, \"tweet\"] = filteredString\n",
    "\n",
    "dfSubject.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfTrain = dfSubject.sample(frac = 0.8, random_state = 20)\n",
    "dfTest = df.drop(dfTrain.index)\n",
    "\n",
    "dfGraphModel = dfTrain.sample(frac = 0.6, random_state = 20)\n",
    "dfDM = dfTrain.drop(dfGraphModel.index)\n",
    "\n",
    "posSubject = dfGraphModel.loc[dfSubject['sentiment'] == 4]\n",
    "negSubject = dfGraphModel.loc[dfSubject['sentiment'] == 0]\n",
    "neutSubject = dfGraphModel.loc[dfSubject['sentiment'] == 2] #there is no neutral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def createGraph(text, wordGraph, frame):\n",
    "    if text:\n",
    "        text = re.sub(r'[^\\w\\s]', '', str(text))\n",
    "        text = text.split()\n",
    "        try:\n",
    "            for x in range(len(text) - frame):\n",
    "                for y in range(1, frame + 1):\n",
    "                    wordGraph.add_edge(text[x], text[x+y])\n",
    "            for x in reversed(range(1, frame + 1)):\n",
    "                for y in reversed(range(1, x)):\n",
    "                    wordGraph.add_edge(text[len(text) - x], text[len(text) - y])\n",
    "        except IndexError:\n",
    "            return createGraph(text, wordGraph, frame-1)\n",
    "        return wordGraph\n",
    "    else:\n",
    "        return wordGraph\n",
    "    \n",
    "def createGraphFromTweet(text, frame):\n",
    "    wordGraph = nx.DiGraph()\n",
    "    if type(text) == str:\n",
    "        print(text)\n",
    "        createGraph(text, wordGraph, frame)\n",
    "    if type(text) == list:\n",
    "        for element in text:\n",
    "            createGraph(element, wordGraph, frame)\n",
    "    return wordGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Harrison Lu\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\Users\\Harrison Lu\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py:2: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "posArrayText = posSubject.as_matrix(columns = posSubject.columns[-1:]).flatten().tolist()\n",
    "negArrayText = negSubject.as_matrix(columns = negSubject.columns[-1:]).flatten().tolist()\n",
    "posWordGraph = createGraphFromTweet(posArrayText, 3)\n",
    "negWordGraph = createGraphFromTweet(negArrayText, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#graph similary based on edge similarity\n",
    "\n",
    "def edgeSimilarity(inputGraph, model):\n",
    "    count = 0\n",
    "    normalizationFactor = 1\n",
    "    edgeList = model.edges()\n",
    "    if len(inputGraph.edges()) <= len(edgeList):\n",
    "        normalizationFactor = len(inputGraph.edges())\n",
    "    else:\n",
    "        normalizationFactor = len(edgeList)\n",
    "    for edge in inputGraph.edges():\n",
    "        if edge in edgeList: count += 1\n",
    "    return count/normalizationFactor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "everyone talking food ! havent eaten im allowed eat sssssh\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-107-f07ac1f45009>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'sentiment'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mwordgraph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreateGraphFromTweet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'tweet'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0medgeSimilarity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwordGraph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mposWordGraph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-106-b4516e9da16d>\u001b[0m in \u001b[0;36medgeSimilarity\u001b[1;34m(inputGraph, model)\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0medge\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputGraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0medges\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0medge\u001b[0m \u001b[1;32min\u001b[0m \u001b[0medgeList\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mcount\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mcount\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mnormalizationFactor\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "#try kNN method\n",
    "from sklearn.neighbors import KNeighborsClassifier as kNN\n",
    "\n",
    "sentimentTweetDict = dfDM.to_dict(orient='index')\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "model = kNN(n_neighbors = 3)\n",
    "\n",
    "for key, value in sentimentTweetDict.items():\n",
    "    X.append(value['sentiment'])\n",
    "    wordgraph = createGraphFromTweet(value['tweet'], 3)\n",
    "    y.append(edgeSimilarity(wordGraph, posWordGraph))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
