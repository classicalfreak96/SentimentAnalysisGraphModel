{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Harrison\n",
      "[nltk_data]     Lu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from io import StringIO\n",
    "import networkx as nx\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize \n",
    "stop_words = set(stopwords.words('english')) \n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier as kNN\n",
    "from sklearn.linear_model import LogisticRegression as logreg\n",
    "from sklearn import svm\n",
    "from sklearn.tree import DecisionTreeClassifier as dectree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# explore data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>ID</th>\n",
       "      <th>date</th>\n",
       "      <th>query</th>\n",
       "      <th>username</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810369</td>\n",
       "      <td>mon apr 06 22:19:45 pdt 2009</td>\n",
       "      <td>no_query</td>\n",
       "      <td>_thespecialone_</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>mon apr 06 22:19:49 pdt 2009</td>\n",
       "      <td>no_query</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>mon apr 06 22:19:53 pdt 2009</td>\n",
       "      <td>no_query</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@kenichan i dived many times for the ball. man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>mon apr 06 22:19:57 pdt 2009</td>\n",
       "      <td>no_query</td>\n",
       "      <td>ellectf</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>mon apr 06 22:19:57 pdt 2009</td>\n",
       "      <td>no_query</td>\n",
       "      <td>karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment          ID                          date     query  \\\n",
       "0          0  1467810369  mon apr 06 22:19:45 pdt 2009  no_query   \n",
       "1          0  1467810672  mon apr 06 22:19:49 pdt 2009  no_query   \n",
       "2          0  1467810917  mon apr 06 22:19:53 pdt 2009  no_query   \n",
       "3          0  1467811184  mon apr 06 22:19:57 pdt 2009  no_query   \n",
       "4          0  1467811193  mon apr 06 22:19:57 pdt 2009  no_query   \n",
       "\n",
       "          username                                               text  \n",
       "0  _thespecialone_  @switchfoot http://twitpic.com/2y1zl - awww, t...  \n",
       "1    scotthamilton  is upset that he can't update his facebook by ...  \n",
       "2         mattycus  @kenichan i dived many times for the ball. man...  \n",
       "3          ellectf    my whole body feels itchy and like its on fire   \n",
       "4           karoli  @nationwideclass no, it's not behaving at all....  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./dataset/sentiment140/data.csv', encoding='latin-1', header = None)\n",
    "df.columns = ['sentiment', 'ID', 'date', 'query', 'username', 'text']\n",
    "\n",
    "df = df.applymap(lambda s: s.lower() if type(s) == str else s)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# splitting entire dataset\n",
    "\n",
    "not used in experiment below yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfTrain = df.sample(frac = 0.8, random_state = 20)\n",
    "dfTest = df.drop(dfTrain.index)\n",
    "\n",
    "dfGraphModel = dfTrain.sample(frac = 0.5, random_state = 20)\n",
    "dfDM = dfTrain.drop(dfGraphModel.index)\n",
    "\n",
    "#subset of the dfTrain dataset, split into positive, negative, and neutral tweets\n",
    "pos = dfGraphModel.loc[df['sentiment'] == 4]\n",
    "neg = dfGraphModel.loc[df['sentiment'] == 0]\n",
    "neut = dfGraphModel.loc[df['sentiment'] == 2]\n",
    "\n",
    "posText = {line[\"ID\"]: line[\"text\"] for index, line in pos.iterrows()}\n",
    "negText = {line[\"ID\"]: line[\"text\"] for index, line in neg.iterrows()}\n",
    "\n",
    "posWords = [line.rstrip('\\n') for line in open('./dataset/positive-words.txt') if line.split() and list(line)[0] != ';']\n",
    "negWords = [line.rstrip('\\n') for line in open('./dataset/negative-words.txt') if line.split() and list(line)[0] != \";\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# filtering by target word \"food\"\n",
    "also removing handles. \n",
    "\n",
    "result in 4000 something tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8440"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subjectTweetsDict = {} # key = index in original df and value = tweet info (sentiment, id, date, query, username, full tweet)\n",
    "filteredTweets = {} # key = index in original df and value = filtered tweet\n",
    "count = 0\n",
    "for row in df.itertuples():\n",
    "    if 'food' in row[6]:\n",
    "        subjectTweetsDict[row[0]] = list(row)[1:7]\n",
    "        word_tokens = str(row[6]).split() #split by white space\n",
    "        filtered_sentence = [w for w in word_tokens if not w in stop_words] \n",
    "        filtered_sentence = [] \n",
    "        i = 0\n",
    "        while i < len(word_tokens):\n",
    "            if '@' in word_tokens[i]: #Taking out handles from tweets\n",
    "                i = i + 1\n",
    "            elif word_tokens[i] not in stop_words:\n",
    "                filtered_sentence.append(word_tokens[i])\n",
    "            i = i + 1\n",
    "        filteredTweets[row[0]] = filtered_sentence\n",
    "#print(subjectTweetsDict)\n",
    "#df2 = pd.DataFrame(data=subjectTweetsDict, columns = ['index', 'sentiment', 'id', 'date', 'query', 'username', 'tweet'])\n",
    "dfSubject= pd.DataFrame.from_dict(subjectTweetsDict, orient = 'index', columns = ['sentiment', 'id', 'date', 'query', 'username', 'text'])\n",
    "for key, value in filteredTweets.items():\n",
    "    filteredString = ' '.join(value)\n",
    "    dfSubject.at[key, \"text\"] = filteredString\n",
    "\n",
    "dfSubject.tail()\n",
    "\n",
    "len(dfSubject)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## splitting our dataset into training, testing set.\n",
    "split training into creating graph model, as well as creating the data mining model. \n",
    "split graph model into positive, negative, and neutral.\n",
    "\n",
    "no neutral tweets, as we have found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfTrain = dfSubject.sample(frac = 0.8, random_state = 20)\n",
    "dfTest = dfSubject.drop(dfTrain.index)\n",
    "\n",
    "dfGraphModel = dfTrain.sample(frac = 0.6, random_state = 20)\n",
    "dfDM = dfTrain.drop(dfGraphModel.index)\n",
    "\n",
    "posSubject = dfGraphModel.loc[dfSubject['sentiment'] == 4]\n",
    "negSubject = dfGraphModel.loc[dfSubject['sentiment'] == 0]\n",
    "neutSubject = dfGraphModel.loc[dfSubject['sentiment'] == 2] #there is no neutral"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# writing functions to evaluate how each model works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''this function creates the word graph given the text in the tweet and the \n",
    "frame that is used to create the graph model. Can accept both an array of strings to \n",
    "treat as one long string, or a single string.'''\n",
    "\n",
    "def createGraphFromTweet(text, frame):\n",
    "    wordGraph = nx.DiGraph()\n",
    "    if type(text) == str:\n",
    "        createGraph(text, wordGraph, frame)\n",
    "    if type(text) == list:\n",
    "        for element in text:\n",
    "            createGraph(element, wordGraph, frame)\n",
    "    return wordGraph\n",
    "\n",
    "'''helper function- NOT FOR USE.'''\n",
    "def createGraph(text, wordGraph, frame):\n",
    "    if text:\n",
    "        text = re.sub(r'[^\\w\\s]', '', str(text))\n",
    "        text = text.split()\n",
    "        try:\n",
    "            if len(text) == 1:\n",
    "                wordGraph.add_edge(text[0], text[0], weight = 1)\n",
    "            for x in range(len(text) - frame):\n",
    "                for y in range(1, frame + 1):\n",
    "                    n1 = text[x]\n",
    "                    n2 = text[x+y]\n",
    "                    if wordGraph.has_edge(n1, n2):\n",
    "                        wordGraph[n1][n2]['weight'] = wordGraph[n1][n2]['weight'] + 1\n",
    "                    else:\n",
    "                        wordGraph.add_edge(n1, n2, weight = 1)\n",
    "            for x in reversed(range(1, frame + 1)):\n",
    "                for y in reversed(range(1, x)):\n",
    "                    n1 = text[len(text) - x]\n",
    "                    n2 = text[len(text) - y]\n",
    "                    if wordGraph.has_edge(n1, n2):\n",
    "                        wordGraph[n1][n2]['weight'] = wordGraph[n1][n2]['weight'] + 1\n",
    "                    else:\n",
    "                        wordGraph.add_edge(n1, n2, weight = 1)\n",
    "        except IndexError:\n",
    "            return createGraph(text, wordGraph, frame-1)\n",
    "        return wordGraph\n",
    "    else:\n",
    "        return wordGraph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Harrison Lu\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py:2: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \n",
      "C:\\Users\\Harrison Lu\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py:3: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "'''extracting text from the dataframe'''\n",
    "posArrayText = posSubject.as_matrix(columns = posSubject.columns[-1:]).flatten().tolist()\n",
    "negArrayText = negSubject.as_matrix(columns = negSubject.columns[-1:]).flatten().tolist()\n",
    "\n",
    "'''putting text into one large graph'''\n",
    "posWordGraph = createGraphFromTweet(posArrayText, 10)\n",
    "negWordGraph = createGraphFromTweet(negArrayText, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''GRAPH SIMILARITY FUNCTIONS'''\n",
    "\n",
    "'''counts the number of identical edges between two graphs, normalizes by the minimum number of nodes in either graph'''\n",
    "def edgeSimilarity(inputGraph, model):\n",
    "    count = 0\n",
    "    for edge in inputGraph.edges():\n",
    "        n1, n2 = edge\n",
    "        if model.has_edge(n1, n2): \n",
    "            count += 1\n",
    "    return count/min(len(inputGraph), len(model))\n",
    "\n",
    "'''returns maximum common subgraph of inputs'''\n",
    "def getMCS(graphModel, tweetGraph):\n",
    "    matching_graph = nx.DiGraph()\n",
    "    for n1, n2 in tweetGraph.edges():\n",
    "        if graphModel.has_edge(n1, n2):\n",
    "            matching_graph.add_edge(n1, n2, weight = tweetGraph[n1][n2]['weight'])\n",
    "    edgeList = list(matching_graph.edges())\n",
    "    edgeListCopy = edgeList[:]\n",
    "    nodeList = list(matching_graph.nodes())\n",
    "    visited = []\n",
    "    graphArray = []\n",
    "    while nodeList:\n",
    "        G = nx.DiGraph()\n",
    "        parentNode = nodeList.pop(0)\n",
    "        toRemove = []\n",
    "        for edge in edgeList:\n",
    "            n1, n2 = edge\n",
    "            if parentNode == n1:\n",
    "                if n2 in nodeList:\n",
    "                    G.add_edge(n1, n2)\n",
    "                    toRemove.append(edge)\n",
    "                    visited.append(n2)\n",
    "                else:\n",
    "                    for graph in graphArray:\n",
    "                        if n2 in graph.nodes():\n",
    "                            graph.add_edge(n1, n2)\n",
    "            edgeList = [e for e in edgeList if e not in toRemove]\n",
    "            toRemove = []\n",
    "            while visited:\n",
    "                node = visited.pop(0)\n",
    "                if node in nodeList:\n",
    "                    nodeList.remove(node)\n",
    "                for edge in edgeList:\n",
    "                    n1, n2 = edge\n",
    "                    if node == n1: \n",
    "                        G.add_edge(n1, n2)\n",
    "                        toRemove.append(edge)\n",
    "                        visited.append(n2)\n",
    "                edgeList = [e for e in edgeList if e not in toRemove]\n",
    "                toRemove = []\n",
    "        if len(G) != 0:\n",
    "            graphArray.append(G)\n",
    "\n",
    "    size = 0 \n",
    "    returnGraph = nx.DiGraph()\n",
    "    for graph in graphArray:\n",
    "        if len(graph) > size:\n",
    "            returnGraph = graph\n",
    "            size = len(graph)\n",
    "    return returnGraph\n",
    "        \n",
    "\n",
    "'''returns number of common nodes in MCS and model graph, normalized by minimum number of nodes'''\n",
    "def MCSNS(mcs_graph, graphModel, tweetGraph):\n",
    "    return len(mcs_graph)/min(len(graphModel),len(tweetGraph))\n",
    "\n",
    "'''returns number of common edges in MCS and model graph, normalized by minimum number of nodes'''\n",
    "def MCSUES(mcs_graph, graphModel, tweetGraph): \n",
    "    return len(mcs_graph.edges())/min(len(graphModel),len(tweetGraph))\n",
    "\n",
    "'''returns number of common edges in the MCS and model graph, taking direction into account,\n",
    "normalized by minimum number of nodes'''\n",
    "def MCSDES(mcs_graph, graphModel, tweetGraph): \n",
    "    count = 0\n",
    "    for e1,e2 in mcs_graph.edges():\n",
    "        if tweetGraph.has_edge(e1,e2) and graphModel.has_edge(e1,e2):\n",
    "            count+=1\n",
    "    return count/min(len(graphModel),len(tweetGraph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''generates the feature vectors and labels (posValue, negValue).\n",
    "   -dataframeDict is the dataframe above turned into a dictionary, with ID as \n",
    "   key and the rest of the information as value, stored as a nested dictionary\n",
    "   -posWordGraph/negWordGraph are our pos/neg graph models\n",
    "   -metric type refers to one of the above functions listed in the above cell block'''\n",
    "def generateWordGraphVectors(dataframeDict, posWordGraph, negWordGraph, metricType):\n",
    "    X = []\n",
    "    y = []\n",
    "    count = 0\n",
    "    for key, value in dataframeDict.items():\n",
    "        if value['text']:\n",
    "            y.append(value['sentiment'])\n",
    "            wordGraph = createGraphFromTweet(value['text'], 4)\n",
    "            posNegArray = []\n",
    "            if metricType == \"edge\":\n",
    "                posNegArray.append(edgeSimilarity(wordGraph, posWordGraph))\n",
    "                posNegArray.append(edgeSimilarity(wordGraph, negWordGraph))\n",
    "            elif metricType == \"MCSNS\":\n",
    "                mcs_graph = getMCS(posWordGraph, wordGraph)\n",
    "                posNegArray.append(MCSNS(mcs_graph, wordGraph, posWordGraph))\n",
    "                mcs_graph = getMCS(negWordGraph, wordGraph)\n",
    "                posNegArray.append(MCSNS(mcs_graph, wordGraph, negWordGraph))\n",
    "            elif metricType == \"MCSUES\":\n",
    "                mcs_graph = getMCS(posWordGraph, wordGraph)\n",
    "                posNegArray.append(MCSUES(mcs_graph, wordGraph, posWordGraph))\n",
    "                mcs_graph = getMCS(negWordGraph, wordGraph)\n",
    "                posNegArray.append(MCSUES(mcs_graph, wordGraph, negWordGraph))\n",
    "            elif metricType == \"MCSDES\":\n",
    "                mcs_graph = getMCS(posWordGraph, wordGraph)\n",
    "                posNegArray.append(MCSDES(mcs_graph, wordGraph, posWordGraph))\n",
    "                mcs_graph = getMCS(negWordGraph, wordGraph)\n",
    "                posNegArray.append(MCSDES(mcs_graph, wordGraph, negWordGraph))\n",
    "            X.append(posNegArray)\n",
    "            count += 1\n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# here we actually start evaluating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''turn our dataframe into dictionary format'''\n",
    "sentimentTweetDict = dfDM.to_dict(orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kNN score: 0.5847156398104265\n",
      "SVM score: 0.6131516587677726\n",
      "Logistic regression score: 0.620260663507109\n",
      "Decision tree score: 0.5562796208530806\n"
     ]
    }
   ],
   "source": [
    "'''evaluate model, vectors generated by edgeSimilarity function. \n",
    "   Model evaluated using kNN, SVM, logistic regression, and decision tree.'''\n",
    "X, y = generateWordGraphVectors(sentimentTweetDict, posWordGraph, negWordGraph, \"edge\")\n",
    "testDict = dfTest.to_dict(orient='index')\n",
    "Xtest, ytest = generateWordGraphVectors(testDict, posWordGraph, negWordGraph, \"edge\")\n",
    "\n",
    "\n",
    "model = kNN(n_neighbors = 5)\n",
    "model.fit(X, y)\n",
    "print(\"kNN score: \" + str(model.score(Xtest, ytest)))\n",
    "\n",
    "classifier = svm.SVC(kernel = \"linear\")\n",
    "classifier.fit(X, y)\n",
    "print(\"SVM score: \" + str(classifier.score(Xtest, ytest)))\n",
    "\n",
    "classifier = logreg()\n",
    "classifier.fit(X, y)\n",
    "print(\"Logistic regression score: \" + str(classifier.score(Xtest, ytest)))\n",
    "\n",
    "classifier = dectree()\n",
    "classifier.fit(X, y)\n",
    "print(\"Decision tree score: \" + str(classifier.score(Xtest, ytest)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kNN score: 0.5201421800947867\n",
      "SVM score: 0.590047393364929\n",
      "Logistic regression score: 0.5864928909952607\n",
      "Decision tree score: 0.556872037914692\n"
     ]
    }
   ],
   "source": [
    "'''identical as above, except vectors generated by MCSNS'''\n",
    "X, y = generateWordGraphVectors(sentimentTweetDict, posWordGraph, negWordGraph, \"MCSNS\")\n",
    "testDict = dfTest.to_dict(orient='index')\n",
    "Xtest, ytest = generateWordGraphVectors(testDict, posWordGraph, negWordGraph, \"MCSNS\")\n",
    "\n",
    "model = kNN(n_neighbors = 5)\n",
    "model.fit(X, y)\n",
    "print(\"kNN score: \" + str(model.score(Xtest, ytest)))\n",
    "\n",
    "classifier = svm.SVC(kernel = \"linear\")\n",
    "classifier.fit(X, y)\n",
    "print(\"SVM score: \" + str(classifier.score(Xtest, ytest)))\n",
    "\n",
    "classifier = logreg()\n",
    "classifier.fit(X, y)\n",
    "print(\"Logistic regression score: \" + str(classifier.score(Xtest, ytest)))\n",
    "\n",
    "classifier = dectree()\n",
    "classifier.fit(X, y)\n",
    "print(\"Decision tree score: \" + str(classifier.score(Xtest, ytest)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kNN score: 0.5669431279620853\n",
      "SVM score: 0.5965639810426541\n",
      "Logistic regression score: 0.6066350710900474\n",
      "Decision tree score: 0.5408767772511849\n"
     ]
    }
   ],
   "source": [
    "'''identical as above, except vectors generated by MCSUES'''\n",
    "X, y = generateWordGraphVectors(sentimentTweetDict, posWordGraph, negWordGraph, \"MCSUES\")\n",
    "testDict = dfTest.to_dict(orient='index')\n",
    "Xtest, ytest = generateWordGraphVectors(testDict, posWordGraph, negWordGraph, \"MCSUES\")\n",
    "\n",
    "model = kNN(n_neighbors = 5)\n",
    "model.fit(X, y)\n",
    "print(\"kNN score: \" + str(model.score(Xtest, ytest)))\n",
    "\n",
    "classifier = svm.SVC(kernel = \"linear\")\n",
    "classifier.fit(X, y)\n",
    "print(\"SVM score: \" + str(classifier.score(Xtest, ytest)))\n",
    "\n",
    "classifier = logreg()\n",
    "classifier.fit(X, y)\n",
    "print(\"Logistic regression score: \" + str(classifier.score(Xtest, ytest)))\n",
    "\n",
    "classifier = dectree()\n",
    "classifier.fit(X, y)\n",
    "print(\"Decision tree score: \" + str(classifier.score(Xtest, ytest)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kNN score: 0.5669431279620853\n",
      "SVM score: 0.5965639810426541\n",
      "Logistic regression score: 0.6066350710900474\n",
      "Decision tree score: 0.5385071090047393\n"
     ]
    }
   ],
   "source": [
    "'''identical as above, except vectors generated by MCSDES'''\n",
    "X, y = generateWordGraphVectors(sentimentTweetDict, posWordGraph, negWordGraph, \"MCSDES\")\n",
    "testDict = dfTest.to_dict(orient='index')\n",
    "Xtest, ytest = generateWordGraphVectors(testDict, posWordGraph, negWordGraph, \"MCSDES\")\n",
    "\n",
    "model = kNN(n_neighbors = 5)\n",
    "model.fit(X, y)\n",
    "print(\"kNN score: \" + str(model.score(Xtest, ytest)))\n",
    "\n",
    "classifier = svm.SVC(kernel = \"linear\")\n",
    "classifier.fit(X, y)\n",
    "print(\"SVM score: \" + str(classifier.score(Xtest, ytest)))\n",
    "\n",
    "classifier = logreg()\n",
    "classifier.fit(X, y)\n",
    "print(\"Logistic regression score: \" + str(classifier.score(Xtest, ytest)))\n",
    "\n",
    "classifier = dectree()\n",
    "classifier.fit(X, y)\n",
    "print(\"Decision tree score: \" + str(classifier.score(Xtest, ytest)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# here we start considering edge weights. \n",
    "weights = how many times the edge appeared."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''remove edges that have under a certain weight, also remove isolated \n",
    "nodes after we run this function.'''\n",
    "def removeEdgesByWeight(graph, threshold):\n",
    "    returnGraph = graph.copy()\n",
    "    edgeCountDict = nx.get_edge_attributes(returnGraph, 'weight')\n",
    "    for key, value in edgeCountDict.items():\n",
    "        if value <= threshold:\n",
    "            returnGraph.remove_edge(*key)\n",
    "    emptyNodes = list(nx.isolates(returnGraph))\n",
    "    returnGraph.remove_nodes_from(emptyNodes)\n",
    "    return returnGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''trim edges'''\n",
    "posWordGraphTrimmed = removeEdgesByWeight(posWordGraph, 1)\n",
    "negWordGraphTrimmed = removeEdgesByWeight(negWordGraph, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kNN score: 0.5989336492890995\n",
      "SVM score: 0.6226303317535545\n",
      "Logistic regression score: 0.6279620853080569\n",
      "Decision tree score: 0.5864928909952607\n"
     ]
    }
   ],
   "source": [
    "'''evaluate, same as above, but with new \"trimmed\" graphs, using edge similarity'''\n",
    "X, y = generateWordGraphVectors(sentimentTweetDict, posWordGraphTrimmed, negWordGraphTrimmed, \"edge\")\n",
    "testDict = dfTest.to_dict(orient='index')\n",
    "Xtest, ytest = generateWordGraphVectors(testDict, posWordGraphTrimmed, negWordGraphTrimmed, \"edge\")\n",
    "\n",
    "model = kNN(n_neighbors = 5)\n",
    "model.fit(X, y)\n",
    "print(\"kNN score: \" + str(model.score(Xtest, ytest)))\n",
    "\n",
    "classifier = svm.SVC(kernel = \"linear\")\n",
    "classifier.fit(X, y)\n",
    "print(\"SVM score: \" + str(classifier.score(Xtest, ytest)))\n",
    "\n",
    "classifier = logreg()\n",
    "classifier.fit(X, y)\n",
    "print(\"Logistic regression score: \" + str(classifier.score(Xtest, ytest)))\n",
    "\n",
    "classifier = dectree()\n",
    "classifier.fit(X, y)\n",
    "print(\"Decision tree score: \" + str(classifier.score(Xtest, ytest)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kNN score: 0.5639810426540285\n",
      "SVM score: 0.5764218009478673\n",
      "Logistic regression score: 0.5930094786729858\n",
      "Decision tree score: 0.5633886255924171\n"
     ]
    }
   ],
   "source": [
    "'''evaluate, same as above, but with new \"trimmed\" graphs, using MCSNS'''\n",
    "X, y = generateWordGraphVectors(sentimentTweetDict, posWordGraphTrimmed, negWordGraphTrimmed, \"MCSNS\")\n",
    "testDict = dfTest.to_dict(orient='index')\n",
    "Xtest, ytest = generateWordGraphVectors(testDict, posWordGraphTrimmed, negWordGraphTrimmed, \"MCSNS\")\n",
    "\n",
    "model = kNN(n_neighbors = 5)\n",
    "model.fit(X, y)\n",
    "print(\"kNN score: \" + str(model.score(Xtest, ytest)))\n",
    "\n",
    "classifier = svm.SVC(kernel = \"linear\")\n",
    "classifier.fit(X, y)\n",
    "print(\"SVM score: \" + str(classifier.score(Xtest, ytest)))\n",
    "\n",
    "classifier = logreg()\n",
    "classifier.fit(X, y)\n",
    "print(\"Logistic regression score: \" + str(classifier.score(Xtest, ytest)))\n",
    "\n",
    "classifier = dectree()\n",
    "classifier.fit(X, y)\n",
    "print(\"Decision tree score: \" + str(classifier.score(Xtest, ytest)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kNN score: 0.5829383886255924\n",
      "SVM score: 0.5995260663507109\n",
      "Logistic regression score: 0.6167061611374408\n",
      "Decision tree score: 0.5651658767772512\n"
     ]
    }
   ],
   "source": [
    "'''evaluate, same as above, but with new \"trimmed\" graphs, using MCSUES'''\n",
    "X, y = generateWordGraphVectors(sentimentTweetDict, posWordGraphTrimmed, negWordGraphTrimmed, \"MCSUES\")\n",
    "testDict = dfTest.to_dict(orient='index')\n",
    "Xtest, ytest = generateWordGraphVectors(testDict, posWordGraphTrimmed, negWordGraphTrimmed, \"MCSUES\")\n",
    "\n",
    "model = kNN(n_neighbors = 5)\n",
    "model.fit(X, y)\n",
    "print(\"kNN score: \" + str(model.score(Xtest, ytest)))\n",
    "\n",
    "classifier = svm.SVC(kernel = \"linear\")\n",
    "classifier.fit(X, y)\n",
    "print(\"SVM score: \" + str(classifier.score(Xtest, ytest)))\n",
    "\n",
    "classifier = logreg()\n",
    "classifier.fit(X, y)\n",
    "print(\"Logistic regression score: \" + str(classifier.score(Xtest, ytest)))\n",
    "\n",
    "classifier = dectree()\n",
    "classifier.fit(X, y)\n",
    "print(\"Decision tree score: \" + str(classifier.score(Xtest, ytest)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kNN score: 0.5657582938388626\n",
      "SVM score: 0.5740521327014217\n",
      "Logistic regression score: 0.601303317535545\n",
      "Decision tree score: 0.5841232227488151\n"
     ]
    }
   ],
   "source": [
    "'''evaluate, same as above, but with new \"trimmed\" graphs, using MCSDES'''\n",
    "X, y = generateWordGraphVectors(sentimentTweetDict, posWordGraphTrimmed, negWordGraphTrimmed, \"MCSDES\")\n",
    "testDict = dfTest.to_dict(orient='index')\n",
    "Xtest, ytest = generateWordGraphVectors(testDict, posWordGraphTrimmed, negWordGraphTrimmed, \"MCSDES\")\n",
    "\n",
    "model = kNN(n_neighbors = 5)\n",
    "model.fit(X, y)\n",
    "print(\"kNN score: \" + str(model.score(Xtest, ytest)))\n",
    "\n",
    "classifier = svm.SVC(kernel = \"linear\")\n",
    "classifier.fit(X, y)\n",
    "print(\"SVM score: \" + str(classifier.score(Xtest, ytest)))\n",
    "\n",
    "classifier = logreg()\n",
    "classifier.fit(X, y)\n",
    "print(\"Logistic regression score: \" + str(classifier.score(Xtest, ytest)))\n",
    "\n",
    "classifier = dectree()\n",
    "classifier.fit(X, y)\n",
    "print(\"Decision tree score: \" + str(classifier.score(Xtest, ytest)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweetGraph = createGraphFromTweet(\"hello this is a good one dont let it go or else it might be a really bad decision\", 3)\n",
    "graphModel = posWordGraph.copy()\n",
    "\n",
    "matching_graph = nx.DiGraph()\n",
    "for n1, n2 in tweetGraph.edges():\n",
    "    if graphModel.has_edge(n1, n2):\n",
    "        matching_graph.add_edge(n1, n2, weight = tweetGraph[n1][n2]['weight'])\n",
    "edgeList = list(matching_graph.edges())\n",
    "edgeListCopy = edgeList[:]\n",
    "nodeList = list(matching_graph.nodes())\n",
    "visited = []\n",
    "graphArray = []\n",
    "while nodeList:\n",
    "    G = nx.DiGraph()\n",
    "    parentNode = nodeList.pop(0)\n",
    "    toRemove = []\n",
    "    for edge in edgeList:\n",
    "        n1, n2 = edge\n",
    "        if parentNode == n1:\n",
    "            if n2 in nodeList:\n",
    "                G.add_edge(n1, n2)\n",
    "                toRemove.append(edge)\n",
    "                visited.append(n2)\n",
    "            else:\n",
    "                for graph in graphArray:\n",
    "                    if n2 in graph.nodes():\n",
    "                        graph.add_edge(n1, n2)\n",
    "        edgeList = [e for e in edgeList if e not in toRemove]\n",
    "        toRemove = []\n",
    "        while visited:\n",
    "            node = visited.pop(0)\n",
    "            if node in nodeList:\n",
    "                nodeList.remove(node)\n",
    "            for edge in edgeList:\n",
    "                n1, n2 = edge\n",
    "                if node == n1: \n",
    "                    G.add_edge(n1, n2)\n",
    "                    toRemove.append(edge)\n",
    "                    visited.append(n2)\n",
    "            edgeList = [e for e in edgeList if e not in toRemove]\n",
    "            toRemove = []\n",
    "    if len(G) != 0:\n",
    "        graphArray.append(G)\n",
    "    \n",
    "size = 0 \n",
    "returnGraph = nx.DiGraph()\n",
    "for graph in graphArray:\n",
    "    if len(graph) >= size:\n",
    "        returnGraph = graph\n",
    "        size = len(graph)\n",
    "return returnGraph\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
